{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd34ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import getopt\n",
    "import collections\n",
    "import tqdm\n",
    "import itertools\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from scipy import stats\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.utils import shuffle\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "import gensim \n",
    "from gensim.models import Word2Vec\n",
    "import sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ce794e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.4-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.10.1)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.24.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b09a3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file read\n",
    "TEST= pd.read_csv(\"kaggle_test.csv\")\n",
    "test= TEST.drop(columns=['ID'])\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "train= pd.read_csv(\"kaggle_train.csv\")\n",
    "\n",
    "x = train.drop(columns=['Labels'])\n",
    "y = train.Labels\n",
    "#Trainig_dataset(df3)_devided_into_80%_&_20%\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train.reset_index(inplace=True, drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "x_valid.reset_index(inplace=True, drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61571c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACAN</th>\n",
       "      <th>AGER</th>\n",
       "      <th>ALPK1</th>\n",
       "      <th>ANKRD17</th>\n",
       "      <th>APOB</th>\n",
       "      <th>APPL1</th>\n",
       "      <th>APPL2</th>\n",
       "      <th>ARRB2</th>\n",
       "      <th>ASGR1</th>\n",
       "      <th>ASGR2</th>\n",
       "      <th>...</th>\n",
       "      <th>UBE2N</th>\n",
       "      <th>UBE2V1</th>\n",
       "      <th>UBQLN1</th>\n",
       "      <th>UFD1</th>\n",
       "      <th>UNC93B1</th>\n",
       "      <th>USP17L2</th>\n",
       "      <th>VCAN</th>\n",
       "      <th>WDFY1</th>\n",
       "      <th>XIAP</th>\n",
       "      <th>ZCCHC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.1211</td>\n",
       "      <td>76.6643</td>\n",
       "      <td>1040.4443</td>\n",
       "      <td>1981.6944</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>1356.1762</td>\n",
       "      <td>519.1270</td>\n",
       "      <td>1425.9563</td>\n",
       "      <td>33.7949</td>\n",
       "      <td>32.8561</td>\n",
       "      <td>...</td>\n",
       "      <td>2187.9058</td>\n",
       "      <td>3674.0734</td>\n",
       "      <td>2921.6929</td>\n",
       "      <td>1793.6228</td>\n",
       "      <td>1523.5860</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>5315.4971</td>\n",
       "      <td>2514.5897</td>\n",
       "      <td>921.5364</td>\n",
       "      <td>564.4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.1116</td>\n",
       "      <td>24.9440</td>\n",
       "      <td>384.7138</td>\n",
       "      <td>2125.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1839.7825</td>\n",
       "      <td>1204.9888</td>\n",
       "      <td>554.8449</td>\n",
       "      <td>3.8375</td>\n",
       "      <td>2.8782</td>\n",
       "      <td>...</td>\n",
       "      <td>2344.0998</td>\n",
       "      <td>1727.8414</td>\n",
       "      <td>3106.4918</td>\n",
       "      <td>1180.0352</td>\n",
       "      <td>554.8449</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>469.7793</td>\n",
       "      <td>1625.8395</td>\n",
       "      <td>1488.3275</td>\n",
       "      <td>316.2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.6118</td>\n",
       "      <td>46.2410</td>\n",
       "      <td>289.7137</td>\n",
       "      <td>2054.7342</td>\n",
       "      <td>3.1456</td>\n",
       "      <td>1212.6455</td>\n",
       "      <td>833.5955</td>\n",
       "      <td>568.7323</td>\n",
       "      <td>10.3806</td>\n",
       "      <td>3.4602</td>\n",
       "      <td>...</td>\n",
       "      <td>2074.8663</td>\n",
       "      <td>3581.3023</td>\n",
       "      <td>2382.5102</td>\n",
       "      <td>1289.0783</td>\n",
       "      <td>384.0830</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13716.8921</td>\n",
       "      <td>1078.0120</td>\n",
       "      <td>2055.6779</td>\n",
       "      <td>631.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.5306</td>\n",
       "      <td>20.7384</td>\n",
       "      <td>625.7589</td>\n",
       "      <td>2485.3028</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>693.9853</td>\n",
       "      <td>969.5957</td>\n",
       "      <td>756.5010</td>\n",
       "      <td>16.5306</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>...</td>\n",
       "      <td>2788.8650</td>\n",
       "      <td>3280.2029</td>\n",
       "      <td>3396.2899</td>\n",
       "      <td>1823.1705</td>\n",
       "      <td>933.5289</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>482.3934</td>\n",
       "      <td>721.9370</td>\n",
       "      <td>1613.3880</td>\n",
       "      <td>453.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.7428</td>\n",
       "      <td>103.6977</td>\n",
       "      <td>247.1865</td>\n",
       "      <td>807.4759</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>702.9743</td>\n",
       "      <td>508.0386</td>\n",
       "      <td>865.3537</td>\n",
       "      <td>30.5466</td>\n",
       "      <td>8.0386</td>\n",
       "      <td>...</td>\n",
       "      <td>2580.3859</td>\n",
       "      <td>4031.7524</td>\n",
       "      <td>3923.2315</td>\n",
       "      <td>2310.6873</td>\n",
       "      <td>1168.4084</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1757.2347</td>\n",
       "      <td>690.5145</td>\n",
       "      <td>945.3376</td>\n",
       "      <td>793.8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>369.5060</td>\n",
       "      <td>158.6931</td>\n",
       "      <td>681.8359</td>\n",
       "      <td>1826.5266</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>1767.7946</td>\n",
       "      <td>730.8440</td>\n",
       "      <td>468.6892</td>\n",
       "      <td>28.0047</td>\n",
       "      <td>3.1116</td>\n",
       "      <td>...</td>\n",
       "      <td>3489.3038</td>\n",
       "      <td>2117.8530</td>\n",
       "      <td>3339.9455</td>\n",
       "      <td>1487.3590</td>\n",
       "      <td>239.9844</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>960.7157</td>\n",
       "      <td>1209.2571</td>\n",
       "      <td>1067.2890</td>\n",
       "      <td>1055.6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>147.4978</td>\n",
       "      <td>300.7024</td>\n",
       "      <td>641.3521</td>\n",
       "      <td>1165.0571</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>658.0334</td>\n",
       "      <td>699.7366</td>\n",
       "      <td>420.9833</td>\n",
       "      <td>7.0237</td>\n",
       "      <td>2.1949</td>\n",
       "      <td>...</td>\n",
       "      <td>2223.0026</td>\n",
       "      <td>2777.0588</td>\n",
       "      <td>5190.9570</td>\n",
       "      <td>1703.6831</td>\n",
       "      <td>849.4293</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1702.3705</td>\n",
       "      <td>1396.4004</td>\n",
       "      <td>1478.9289</td>\n",
       "      <td>590.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>26.3342</td>\n",
       "      <td>58.8318</td>\n",
       "      <td>44.2639</td>\n",
       "      <td>661.1570</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>777.1397</td>\n",
       "      <td>535.0889</td>\n",
       "      <td>1495.4475</td>\n",
       "      <td>2.8015</td>\n",
       "      <td>1.1206</td>\n",
       "      <td>...</td>\n",
       "      <td>2274.2681</td>\n",
       "      <td>3895.2234</td>\n",
       "      <td>1603.5859</td>\n",
       "      <td>2339.2464</td>\n",
       "      <td>2005.8832</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>531.1668</td>\n",
       "      <td>1018.0698</td>\n",
       "      <td>708.7827</td>\n",
       "      <td>1170.4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>202.5365</td>\n",
       "      <td>82.0063</td>\n",
       "      <td>101.4589</td>\n",
       "      <td>1230.8573</td>\n",
       "      <td>2.6700</td>\n",
       "      <td>1095.8329</td>\n",
       "      <td>2484.2186</td>\n",
       "      <td>527.1288</td>\n",
       "      <td>13.7313</td>\n",
       "      <td>3.8142</td>\n",
       "      <td>...</td>\n",
       "      <td>2334.7001</td>\n",
       "      <td>2370.5235</td>\n",
       "      <td>4404.3101</td>\n",
       "      <td>1740.4329</td>\n",
       "      <td>807.8573</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7289.7874</td>\n",
       "      <td>1231.2387</td>\n",
       "      <td>1445.9807</td>\n",
       "      <td>752.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.6498</td>\n",
       "      <td>46.5600</td>\n",
       "      <td>853.2223</td>\n",
       "      <td>1550.4874</td>\n",
       "      <td>3.0283</td>\n",
       "      <td>375.1301</td>\n",
       "      <td>627.6143</td>\n",
       "      <td>801.7413</td>\n",
       "      <td>5.2995</td>\n",
       "      <td>10.5990</td>\n",
       "      <td>...</td>\n",
       "      <td>1968.0136</td>\n",
       "      <td>2558.5388</td>\n",
       "      <td>3056.3074</td>\n",
       "      <td>1362.3394</td>\n",
       "      <td>1016.3717</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1704.1734</td>\n",
       "      <td>810.0691</td>\n",
       "      <td>944.8282</td>\n",
       "      <td>554.5566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACAN      AGER      ALPK1    ANKRD17    APOB      APPL1      APPL2  \\\n",
       "0     44.1211   76.6643  1040.4443  1981.6944  0.6258  1356.1762   519.1270   \n",
       "1     13.1116   24.9440   384.7138  2125.0400  0.0000  1839.7825  1204.9888   \n",
       "2     45.6118   46.2410   289.7137  2054.7342  3.1456  1212.6455   833.5955   \n",
       "3     16.5306   20.7384   625.7589  2485.3028  0.6011   693.9853   969.5957   \n",
       "4    154.7428  103.6977   247.1865   807.4759  0.4019   702.9743   508.0386   \n",
       "..        ...       ...        ...        ...     ...        ...        ...   \n",
       "196  369.5060  158.6931   681.8359  1826.5266  0.3890  1767.7946   730.8440   \n",
       "197  147.4978  300.7024   641.3521  1165.0571  0.4390   658.0334   699.7366   \n",
       "198   26.3342   58.8318    44.2639   661.1570  0.5603   777.1397   535.0889   \n",
       "199  202.5365   82.0063   101.4589  1230.8573  2.6700  1095.8329  2484.2186   \n",
       "200    2.6498   46.5600   853.2223  1550.4874  3.0283   375.1301   627.6143   \n",
       "\n",
       "         ARRB2    ASGR1    ASGR2  ...      UBE2N     UBE2V1     UBQLN1  \\\n",
       "0    1425.9563  33.7949  32.8561  ...  2187.9058  3674.0734  2921.6929   \n",
       "1     554.8449   3.8375   2.8782  ...  2344.0998  1727.8414  3106.4918   \n",
       "2     568.7323  10.3806   3.4602  ...  2074.8663  3581.3023  2382.5102   \n",
       "3     756.5010  16.5306   0.9017  ...  2788.8650  3280.2029  3396.2899   \n",
       "4     865.3537  30.5466   8.0386  ...  2580.3859  4031.7524  3923.2315   \n",
       "..         ...      ...      ...  ...        ...        ...        ...   \n",
       "196   468.6892  28.0047   3.1116  ...  3489.3038  2117.8530  3339.9455   \n",
       "197   420.9833   7.0237   2.1949  ...  2223.0026  2777.0588  5190.9570   \n",
       "198  1495.4475   2.8015   1.1206  ...  2274.2681  3895.2234  1603.5859   \n",
       "199   527.1288  13.7313   3.8142  ...  2334.7001  2370.5235  4404.3101   \n",
       "200   801.7413   5.2995  10.5990  ...  1968.0136  2558.5388  3056.3074   \n",
       "\n",
       "          UFD1    UNC93B1  USP17L2        VCAN      WDFY1       XIAP  \\\n",
       "0    1793.6228  1523.5860   0.3129   5315.4971  2514.5897   921.5364   \n",
       "1    1180.0352   554.8449   0.3198    469.7793  1625.8395  1488.3275   \n",
       "2    1289.0783   384.0830   0.0000  13716.8921  1078.0120  2055.6779   \n",
       "3    1823.1705   933.5289   0.0000    482.3934   721.9370  1613.3880   \n",
       "4    2310.6873  1168.4084   0.0000   1757.2347   690.5145   945.3376   \n",
       "..         ...        ...      ...         ...        ...        ...   \n",
       "196  1487.3590   239.9844   0.0000    960.7157  1209.2571  1067.2890   \n",
       "197  1703.6831   849.4293   0.0000   1702.3705  1396.4004  1478.9289   \n",
       "198  2339.2464  2005.8832   0.0000    531.1668  1018.0698   708.7827   \n",
       "199  1740.4329   807.8573   0.0000   7289.7874  1231.2387  1445.9807   \n",
       "200  1362.3394  1016.3717   0.0000   1704.1734   810.0691   944.8282   \n",
       "\n",
       "        ZCCHC3  \n",
       "0     564.4997  \n",
       "1     316.2776  \n",
       "2     631.0160  \n",
       "3     453.5400  \n",
       "4     793.8103  \n",
       "..         ...  \n",
       "196  1055.6204  \n",
       "197   590.8692  \n",
       "198  1170.4721  \n",
       "199   752.9322  \n",
       "200   554.5566  \n",
       "\n",
       "[201 rows x 318 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abc051cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 318)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8525ae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 318 features.\n",
      "Fitting estimator with 317 features.\n",
      "Fitting estimator with 316 features.\n",
      "Fitting estimator with 315 features.\n",
      "Fitting estimator with 314 features.\n",
      "Fitting estimator with 313 features.\n",
      "Fitting estimator with 312 features.\n",
      "Fitting estimator with 311 features.\n",
      "Fitting estimator with 310 features.\n",
      "Fitting estimator with 309 features.\n",
      "Fitting estimator with 308 features.\n",
      "Fitting estimator with 307 features.\n",
      "Fitting estimator with 306 features.\n",
      "Fitting estimator with 305 features.\n",
      "Fitting estimator with 304 features.\n",
      "Fitting estimator with 303 features.\n",
      "Fitting estimator with 302 features.\n",
      "Fitting estimator with 301 features.\n",
      "Fitting estimator with 300 features.\n",
      "Fitting estimator with 299 features.\n",
      "Fitting estimator with 298 features.\n",
      "Fitting estimator with 297 features.\n",
      "Fitting estimator with 296 features.\n",
      "Fitting estimator with 295 features.\n",
      "Fitting estimator with 294 features.\n",
      "Fitting estimator with 293 features.\n",
      "Fitting estimator with 292 features.\n",
      "Fitting estimator with 291 features.\n",
      "Fitting estimator with 290 features.\n",
      "Fitting estimator with 289 features.\n",
      "Fitting estimator with 288 features.\n",
      "Fitting estimator with 287 features.\n",
      "Fitting estimator with 286 features.\n",
      "Fitting estimator with 285 features.\n",
      "Fitting estimator with 284 features.\n",
      "Fitting estimator with 283 features.\n",
      "Fitting estimator with 282 features.\n",
      "Fitting estimator with 281 features.\n",
      "Fitting estimator with 280 features.\n",
      "Fitting estimator with 279 features.\n",
      "Fitting estimator with 278 features.\n",
      "Fitting estimator with 277 features.\n",
      "Fitting estimator with 276 features.\n",
      "Fitting estimator with 275 features.\n",
      "Fitting estimator with 274 features.\n",
      "Fitting estimator with 273 features.\n",
      "Fitting estimator with 272 features.\n",
      "Fitting estimator with 271 features.\n",
      "Fitting estimator with 270 features.\n",
      "Fitting estimator with 269 features.\n",
      "Fitting estimator with 268 features.\n",
      "Fitting estimator with 267 features.\n",
      "Fitting estimator with 266 features.\n",
      "Fitting estimator with 265 features.\n",
      "Fitting estimator with 264 features.\n",
      "Fitting estimator with 263 features.\n",
      "Fitting estimator with 262 features.\n",
      "Fitting estimator with 261 features.\n",
      "Fitting estimator with 260 features.\n",
      "Fitting estimator with 259 features.\n",
      "Fitting estimator with 258 features.\n",
      "Fitting estimator with 257 features.\n",
      "Fitting estimator with 256 features.\n",
      "Fitting estimator with 255 features.\n",
      "Fitting estimator with 254 features.\n",
      "Fitting estimator with 253 features.\n",
      "Fitting estimator with 252 features.\n",
      "Fitting estimator with 251 features.\n",
      "Fitting estimator with 250 features.\n",
      "Fitting estimator with 249 features.\n",
      "Fitting estimator with 248 features.\n",
      "Fitting estimator with 247 features.\n",
      "Fitting estimator with 246 features.\n",
      "Fitting estimator with 245 features.\n",
      "Fitting estimator with 244 features.\n",
      "Fitting estimator with 243 features.\n",
      "Fitting estimator with 242 features.\n",
      "Fitting estimator with 241 features.\n",
      "Fitting estimator with 240 features.\n",
      "Fitting estimator with 239 features.\n",
      "Fitting estimator with 238 features.\n",
      "Fitting estimator with 237 features.\n",
      "Fitting estimator with 236 features.\n",
      "Fitting estimator with 235 features.\n",
      "Fitting estimator with 234 features.\n",
      "Fitting estimator with 233 features.\n",
      "Fitting estimator with 232 features.\n",
      "Fitting estimator with 231 features.\n",
      "Fitting estimator with 230 features.\n",
      "Fitting estimator with 229 features.\n",
      "Fitting estimator with 228 features.\n",
      "Fitting estimator with 227 features.\n",
      "Fitting estimator with 226 features.\n",
      "Fitting estimator with 225 features.\n",
      "Fitting estimator with 224 features.\n",
      "Fitting estimator with 223 features.\n",
      "Fitting estimator with 222 features.\n",
      "Fitting estimator with 221 features.\n",
      "Fitting estimator with 220 features.\n",
      "Fitting estimator with 219 features.\n",
      "Fitting estimator with 218 features.\n",
      "Fitting estimator with 217 features.\n",
      "Fitting estimator with 216 features.\n",
      "Fitting estimator with 215 features.\n",
      "Fitting estimator with 214 features.\n",
      "Fitting estimator with 213 features.\n",
      "Fitting estimator with 212 features.\n",
      "Fitting estimator with 211 features.\n",
      "Fitting estimator with 210 features.\n",
      "Fitting estimator with 209 features.\n",
      "Fitting estimator with 208 features.\n",
      "Fitting estimator with 207 features.\n",
      "Fitting estimator with 206 features.\n",
      "Fitting estimator with 205 features.\n",
      "Fitting estimator with 204 features.\n",
      "Fitting estimator with 203 features.\n",
      "Fitting estimator with 202 features.\n",
      "Fitting estimator with 201 features.\n",
      "Fitting estimator with 200 features.\n",
      "Fitting estimator with 199 features.\n",
      "Fitting estimator with 198 features.\n",
      "Fitting estimator with 197 features.\n",
      "Fitting estimator with 196 features.\n",
      "Fitting estimator with 195 features.\n",
      "Fitting estimator with 194 features.\n",
      "Fitting estimator with 193 features.\n",
      "Fitting estimator with 192 features.\n",
      "Fitting estimator with 191 features.\n",
      "Fitting estimator with 190 features.\n",
      "Fitting estimator with 189 features.\n",
      "Fitting estimator with 188 features.\n",
      "Fitting estimator with 187 features.\n",
      "Fitting estimator with 186 features.\n",
      "Fitting estimator with 185 features.\n",
      "Fitting estimator with 184 features.\n",
      "Fitting estimator with 183 features.\n",
      "Fitting estimator with 182 features.\n",
      "Fitting estimator with 181 features.\n",
      "Fitting estimator with 180 features.\n",
      "Fitting estimator with 179 features.\n",
      "Fitting estimator with 178 features.\n",
      "Fitting estimator with 177 features.\n",
      "Fitting estimator with 176 features.\n",
      "Fitting estimator with 175 features.\n",
      "Fitting estimator with 174 features.\n",
      "Fitting estimator with 173 features.\n",
      "Fitting estimator with 172 features.\n",
      "Fitting estimator with 171 features.\n",
      "Fitting estimator with 170 features.\n",
      "Fitting estimator with 169 features.\n",
      "Fitting estimator with 168 features.\n",
      "Fitting estimator with 167 features.\n",
      "Fitting estimator with 166 features.\n",
      "Fitting estimator with 165 features.\n",
      "Fitting estimator with 164 features.\n",
      "Fitting estimator with 163 features.\n",
      "Fitting estimator with 162 features.\n",
      "Fitting estimator with 161 features.\n",
      "Fitting estimator with 160 features.\n",
      "Fitting estimator with 159 features.\n",
      "Fitting estimator with 158 features.\n",
      "Fitting estimator with 157 features.\n",
      "Fitting estimator with 156 features.\n",
      "Fitting estimator with 155 features.\n",
      "Fitting estimator with 154 features.\n",
      "Fitting estimator with 153 features.\n",
      "Fitting estimator with 152 features.\n",
      "Fitting estimator with 151 features.\n",
      "Fitting estimator with 150 features.\n",
      "Fitting estimator with 149 features.\n",
      "Fitting estimator with 148 features.\n",
      "Fitting estimator with 147 features.\n",
      "Fitting estimator with 146 features.\n",
      "Fitting estimator with 145 features.\n",
      "Fitting estimator with 144 features.\n",
      "Fitting estimator with 143 features.\n",
      "Fitting estimator with 142 features.\n",
      "Fitting estimator with 141 features.\n",
      "Fitting estimator with 140 features.\n",
      "Fitting estimator with 139 features.\n",
      "Fitting estimator with 138 features.\n",
      "Fitting estimator with 137 features.\n",
      "Fitting estimator with 136 features.\n",
      "Fitting estimator with 135 features.\n",
      "Fitting estimator with 134 features.\n",
      "Fitting estimator with 133 features.\n",
      "Fitting estimator with 132 features.\n",
      "Fitting estimator with 131 features.\n",
      "Fitting estimator with 130 features.\n",
      "Fitting estimator with 129 features.\n",
      "Fitting estimator with 128 features.\n",
      "Fitting estimator with 127 features.\n",
      "Fitting estimator with 126 features.\n",
      "Fitting estimator with 125 features.\n",
      "Fitting estimator with 124 features.\n",
      "Fitting estimator with 123 features.\n",
      "Fitting estimator with 122 features.\n",
      "Fitting estimator with 121 features.\n",
      "Fitting estimator with 120 features.\n",
      "Fitting estimator with 119 features.\n",
      "Fitting estimator with 118 features.\n",
      "Fitting estimator with 117 features.\n",
      "Fitting estimator with 116 features.\n",
      "Fitting estimator with 115 features.\n",
      "Fitting estimator with 114 features.\n",
      "Fitting estimator with 113 features.\n",
      "Fitting estimator with 112 features.\n",
      "Fitting estimator with 111 features.\n",
      "Fitting estimator with 110 features.\n",
      "Fitting estimator with 109 features.\n",
      "Fitting estimator with 108 features.\n",
      "Fitting estimator with 107 features.\n",
      "Fitting estimator with 106 features.\n",
      "Fitting estimator with 105 features.\n",
      "Fitting estimator with 104 features.\n",
      "Fitting estimator with 103 features.\n",
      "Fitting estimator with 102 features.\n",
      "Fitting estimator with 101 features.\n",
      "Fitting estimator with 100 features.\n",
      "Fitting estimator with 99 features.\n",
      "Fitting estimator with 98 features.\n",
      "Fitting estimator with 97 features.\n",
      "Fitting estimator with 96 features.\n",
      "Fitting estimator with 95 features.\n",
      "Fitting estimator with 94 features.\n",
      "Fitting estimator with 93 features.\n",
      "Fitting estimator with 92 features.\n",
      "Fitting estimator with 91 features.\n",
      "Fitting estimator with 90 features.\n",
      "Fitting estimator with 89 features.\n",
      "Fitting estimator with 88 features.\n",
      "Fitting estimator with 87 features.\n",
      "Fitting estimator with 86 features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 85 features.\n",
      "Fitting estimator with 84 features.\n",
      "Fitting estimator with 83 features.\n",
      "Fitting estimator with 82 features.\n",
      "Fitting estimator with 81 features.\n",
      "Fitting estimator with 80 features.\n",
      "Fitting estimator with 79 features.\n",
      "Fitting estimator with 78 features.\n",
      "Fitting estimator with 77 features.\n",
      "Fitting estimator with 76 features.\n",
      "Fitting estimator with 75 features.\n",
      "Fitting estimator with 74 features.\n",
      "Fitting estimator with 73 features.\n",
      "Fitting estimator with 72 features.\n",
      "Fitting estimator with 71 features.\n",
      "Fitting estimator with 70 features.\n",
      "Fitting estimator with 69 features.\n",
      "Fitting estimator with 68 features.\n",
      "Fitting estimator with 67 features.\n",
      "Fitting estimator with 66 features.\n",
      "Fitting estimator with 65 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#model = LogisticRegression(solver='liblinear')\n",
    "#model = RandomForestRegressor( n_jobs=-1)\n",
    "#model = SVR(kernel='linear')\n",
    "#model = KNeighborsRegressor()\n",
    "model = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "rfe = RFE(estimator=model, verbose=2)\n",
    "sf = rfe.fit(x_train, y_train)  # It learns relationship and transfrom the data\n",
    "sc = x_train.columns[rfe.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "x2_rfe50=x_train[sc] #This will show the first few rows of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e833724c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  44.1211,   76.6643, 1040.4443, ..., 2514.5897,  921.5364,\n",
       "         564.4997],\n",
       "       [  13.1116,   24.944 ,  384.7138, ..., 1625.8395, 1488.3275,\n",
       "         316.2776],\n",
       "       [  45.6118,   46.241 ,  289.7137, ..., 1078.012 , 2055.6779,\n",
       "         631.016 ],\n",
       "       ...,\n",
       "       [  26.3342,   58.8318,   44.2639, ..., 1018.0698,  708.7827,\n",
       "        1170.4721],\n",
       "       [ 202.5365,   82.0063,  101.4589, ..., 1231.2387, 1445.9807,\n",
       "         752.9322],\n",
       "       [   2.6498,   46.56  ,  853.2223, ...,  810.0691,  944.8282,\n",
       "         554.5566]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b3fa5c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=1)\n",
    "X_train = selector.fit_transform(np.array(x_train))\n",
    "x_test = selector.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "689e00c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51, 312)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "56c35c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list = [svm.SVC(kernel='linear',random_state=1, probability=True), xgboost.XGBClassifier(random_state=1, n_jobs= -1), RandomForestClassifier(random_state=1, n_jobs= -1),\n",
    "                   ExtraTreesClassifier(random_state=1, n_jobs= -1), MLPClassifier(random_state=1),\n",
    "                   GradientBoostingClassifier(random_state=1),DecisionTreeClassifier(random_state=1), \n",
    "                   LogisticRegression(random_state=0, n_jobs= -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "40d98dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear', probability=True, random_state=1)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              predictor=None, random_state=1, ...)\n",
      "RandomForestClassifier(n_jobs=-1, random_state=1)\n",
      "ExtraTreesClassifier(n_jobs=-1, random_state=1)\n",
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n",
      "DecisionTreeClassifier(random_state=1)\n",
      "LogisticRegression(n_jobs=-1, random_state=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.603810</td>\n",
       "      <td>0.578431</td>\n",
       "      <td>0.582317</td>\n",
       "      <td>0.164301</td>\n",
       "      <td>0.567765</td>\n",
       "      <td>0.612964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.575250</td>\n",
       "      <td>0.567317</td>\n",
       "      <td>0.138041</td>\n",
       "      <td>0.552546</td>\n",
       "      <td>0.626476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.049689</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.563665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.544286</td>\n",
       "      <td>0.527401</td>\n",
       "      <td>0.522439</td>\n",
       "      <td>0.043884</td>\n",
       "      <td>0.510598</td>\n",
       "      <td>0.572286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.574762</td>\n",
       "      <td>0.532282</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.020363</td>\n",
       "      <td>0.473850</td>\n",
       "      <td>0.567702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.267081</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.590839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.532857</td>\n",
       "      <td>0.548404</td>\n",
       "      <td>0.546829</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>0.550513</td>\n",
       "      <td>0.551821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.258117</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.648292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.662381</td>\n",
       "      <td>0.611503</td>\n",
       "      <td>0.601463</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>0.572758</td>\n",
       "      <td>0.615762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.244932</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.515238</td>\n",
       "      <td>0.508403</td>\n",
       "      <td>0.512439</td>\n",
       "      <td>0.025174</td>\n",
       "      <td>0.508322</td>\n",
       "      <td>0.512619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.198165</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.596273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.544762</td>\n",
       "      <td>0.565623</td>\n",
       "      <td>0.572317</td>\n",
       "      <td>0.145451</td>\n",
       "      <td>0.580365</td>\n",
       "      <td>0.606429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.029503</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.588509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TP    FP    FN    TN      SENS      SPEC      PREC       ACC       MCC  \\\n",
       "0   11.2   8.0   8.8  12.2  0.560000  0.603810  0.578431  0.582317  0.164301   \n",
       "1   13.0  10.0  15.0  13.0  0.464286  0.565217  0.565217  0.509804  0.029503   \n",
       "2   10.8   8.2   9.2  12.0  0.540000  0.595238  0.575250  0.567317  0.138041   \n",
       "3   16.0  12.0  12.0  11.0  0.571429  0.478261  0.571429  0.529412  0.049689   \n",
       "4   10.0   9.2  10.0  11.0  0.500000  0.544286  0.527401  0.522439  0.043884   \n",
       "5   14.0   9.0  14.0  14.0  0.500000  0.608696  0.608696  0.549020  0.108696   \n",
       "6    8.8   8.6  11.2  11.6  0.440000  0.574762  0.532282  0.507317  0.020363   \n",
       "7   16.0   7.0  12.0  16.0  0.571429  0.695652  0.695652  0.627451  0.267081   \n",
       "8   11.2   9.4   8.8  10.8  0.560000  0.532857  0.548404  0.546829  0.094342   \n",
       "9   17.0   8.0  11.0  15.0  0.607143  0.652174  0.680000  0.627451  0.258117   \n",
       "10  10.8   6.8   9.2  13.4  0.540000  0.662381  0.611503  0.601463  0.203891   \n",
       "11  19.0  10.0   9.0  13.0  0.678571  0.565217  0.655172  0.627451  0.244932   \n",
       "12  10.2   9.8   9.8  10.4  0.510000  0.515238  0.508403  0.512439  0.025174   \n",
       "13  20.0  12.0   8.0  11.0  0.714286  0.478261  0.625000  0.607843  0.198165   \n",
       "14  12.0   9.2   8.0  11.0  0.600000  0.544762  0.565623  0.572317  0.145451   \n",
       "15  13.0  10.0  15.0  13.0  0.464286  0.565217  0.565217  0.509804  0.029503   \n",
       "\n",
       "          F1       AUC  \n",
       "0   0.567765  0.612964  \n",
       "1   0.509804  0.571429  \n",
       "2   0.552546  0.626476  \n",
       "3   0.571429  0.563665  \n",
       "4   0.510598  0.572286  \n",
       "5   0.549020  0.571429  \n",
       "6   0.473850  0.567702  \n",
       "7   0.627451  0.590839  \n",
       "8   0.550513  0.551821  \n",
       "9   0.641509  0.648292  \n",
       "10  0.572758  0.615762  \n",
       "11  0.666667  0.631988  \n",
       "12  0.508322  0.512619  \n",
       "13  0.666667  0.596273  \n",
       "14  0.580365  0.606429  \n",
       "15  0.509804  0.588509  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "def calc_metrics(cf_matrix):\n",
    "  tn = cf_matrix[0]\n",
    "  fp = cf_matrix[1]\n",
    "  fn = cf_matrix[2]\n",
    "  tp = cf_matrix[3]\n",
    "  if (((tp+fn)==0)|((tn+fp)==0)|((tp+fp)==0)|((tn+fp)==0)|((tn+fn)==0)):\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = 0\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = 0\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "  else: \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5)\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train, y_train):\n",
    "        train_x = x_train.iloc[train,:]\n",
    "        test_x = x_train.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_valid)[:,1]\n",
    "    predict_label_y = clf.predict(x_valid)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c12772e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>308</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>311</th>\n",
       "      <th>312</th>\n",
       "      <th>313</th>\n",
       "      <th>314</th>\n",
       "      <th>315</th>\n",
       "      <th>316</th>\n",
       "      <th>317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.047811</td>\n",
       "      <td>-0.232069</td>\n",
       "      <td>2.303185</td>\n",
       "      <td>0.370076</td>\n",
       "      <td>-0.184502</td>\n",
       "      <td>0.680110</td>\n",
       "      <td>-0.857634</td>\n",
       "      <td>0.938434</td>\n",
       "      <td>0.525521</td>\n",
       "      <td>2.816893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033111</td>\n",
       "      <td>0.666830</td>\n",
       "      <td>-0.118487</td>\n",
       "      <td>0.474523</td>\n",
       "      <td>0.129464</td>\n",
       "      <td>0.793520</td>\n",
       "      <td>1.773637</td>\n",
       "      <td>2.455994</td>\n",
       "      <td>-0.847773</td>\n",
       "      <td>-0.406053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.406750</td>\n",
       "      <td>-1.007469</td>\n",
       "      <td>-0.323837</td>\n",
       "      <td>0.584374</td>\n",
       "      <td>-0.197406</td>\n",
       "      <td>1.759087</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>-0.790662</td>\n",
       "      <td>-0.589127</td>\n",
       "      <td>-0.553297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330024</td>\n",
       "      <td>-1.159163</td>\n",
       "      <td>0.098005</td>\n",
       "      <td>-0.723138</td>\n",
       "      <td>-0.854023</td>\n",
       "      <td>0.819247</td>\n",
       "      <td>-0.413771</td>\n",
       "      <td>0.838218</td>\n",
       "      <td>0.099293</td>\n",
       "      <td>-1.226462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030556</td>\n",
       "      <td>-0.688181</td>\n",
       "      <td>-0.704432</td>\n",
       "      <td>0.479268</td>\n",
       "      <td>-0.132542</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>-0.175965</td>\n",
       "      <td>-0.763096</td>\n",
       "      <td>-0.345673</td>\n",
       "      <td>-0.487867</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181768</td>\n",
       "      <td>0.579791</td>\n",
       "      <td>-0.750139</td>\n",
       "      <td>-0.510297</td>\n",
       "      <td>-1.027384</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>5.566115</td>\n",
       "      <td>-0.158983</td>\n",
       "      <td>1.047293</td>\n",
       "      <td>-0.186207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.367174</td>\n",
       "      <td>-1.070520</td>\n",
       "      <td>0.641850</td>\n",
       "      <td>1.122959</td>\n",
       "      <td>-0.185011</td>\n",
       "      <td>-0.797308</td>\n",
       "      <td>0.118841</td>\n",
       "      <td>-0.390388</td>\n",
       "      <td>-0.116845</td>\n",
       "      <td>-0.775500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.175490</td>\n",
       "      <td>0.297293</td>\n",
       "      <td>0.437503</td>\n",
       "      <td>0.532198</td>\n",
       "      <td>-0.469575</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>-0.408076</td>\n",
       "      <td>-0.807140</td>\n",
       "      <td>0.308259</td>\n",
       "      <td>-0.772790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.232648</td>\n",
       "      <td>0.173221</td>\n",
       "      <td>-0.874806</td>\n",
       "      <td>-1.385354</td>\n",
       "      <td>-0.189119</td>\n",
       "      <td>-0.777253</td>\n",
       "      <td>-0.881671</td>\n",
       "      <td>-0.174323</td>\n",
       "      <td>0.404659</td>\n",
       "      <td>0.026848</td>\n",
       "      <td>...</td>\n",
       "      <td>0.779187</td>\n",
       "      <td>1.002412</td>\n",
       "      <td>1.054814</td>\n",
       "      <td>1.483782</td>\n",
       "      <td>-0.231120</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>-0.864338</td>\n",
       "      <td>-0.808003</td>\n",
       "      <td>0.351851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3.718558</td>\n",
       "      <td>0.997723</td>\n",
       "      <td>0.866509</td>\n",
       "      <td>0.138103</td>\n",
       "      <td>-0.189385</td>\n",
       "      <td>1.598474</td>\n",
       "      <td>-0.398698</td>\n",
       "      <td>-0.961675</td>\n",
       "      <td>0.310080</td>\n",
       "      <td>-0.527057</td>\n",
       "      <td>...</td>\n",
       "      <td>2.506972</td>\n",
       "      <td>-0.793247</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>-0.123273</td>\n",
       "      <td>-1.173676</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>-0.192157</td>\n",
       "      <td>0.079920</td>\n",
       "      <td>-0.604231</td>\n",
       "      <td>1.217170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.148787</td>\n",
       "      <td>3.126753</td>\n",
       "      <td>0.704320</td>\n",
       "      <td>-0.850779</td>\n",
       "      <td>-0.188354</td>\n",
       "      <td>-0.877520</td>\n",
       "      <td>-0.466129</td>\n",
       "      <td>-1.056368</td>\n",
       "      <td>-0.470575</td>\n",
       "      <td>-0.630115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099828</td>\n",
       "      <td>-0.174767</td>\n",
       "      <td>2.539953</td>\n",
       "      <td>0.298970</td>\n",
       "      <td>-0.554954</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>0.142634</td>\n",
       "      <td>0.420574</td>\n",
       "      <td>0.083588</td>\n",
       "      <td>-0.318898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.253696</td>\n",
       "      <td>-0.499417</td>\n",
       "      <td>-1.687765</td>\n",
       "      <td>-1.604098</td>\n",
       "      <td>-0.185853</td>\n",
       "      <td>-0.611782</td>\n",
       "      <td>-0.823034</td>\n",
       "      <td>1.076369</td>\n",
       "      <td>-0.627674</td>\n",
       "      <td>-0.750890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197280</td>\n",
       "      <td>0.874318</td>\n",
       "      <td>-1.662648</td>\n",
       "      <td>1.539526</td>\n",
       "      <td>0.619102</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>-0.386060</td>\n",
       "      <td>-0.268095</td>\n",
       "      <td>-1.203269</td>\n",
       "      <td>1.596772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.785866</td>\n",
       "      <td>-0.151980</td>\n",
       "      <td>-1.458628</td>\n",
       "      <td>-0.752409</td>\n",
       "      <td>-0.142349</td>\n",
       "      <td>0.099256</td>\n",
       "      <td>3.402072</td>\n",
       "      <td>-0.845676</td>\n",
       "      <td>-0.221001</td>\n",
       "      <td>-0.448069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312156</td>\n",
       "      <td>-0.556186</td>\n",
       "      <td>1.618397</td>\n",
       "      <td>0.370702</td>\n",
       "      <td>-0.597159</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>2.664853</td>\n",
       "      <td>0.119933</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>0.216743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.527846</td>\n",
       "      <td>-0.683398</td>\n",
       "      <td>1.553126</td>\n",
       "      <td>-0.274569</td>\n",
       "      <td>-0.134961</td>\n",
       "      <td>-1.508708</td>\n",
       "      <td>-0.622468</td>\n",
       "      <td>-0.300590</td>\n",
       "      <td>-0.534729</td>\n",
       "      <td>0.314695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384887</td>\n",
       "      <td>-0.379786</td>\n",
       "      <td>0.039214</td>\n",
       "      <td>-0.367299</td>\n",
       "      <td>-0.385471</td>\n",
       "      <td>-0.373156</td>\n",
       "      <td>0.143448</td>\n",
       "      <td>-0.646715</td>\n",
       "      <td>-0.808854</td>\n",
       "      <td>-0.438916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -0.047811 -0.232069  2.303185  0.370076 -0.184502  0.680110 -0.857634   \n",
       "1   -0.406750 -1.007469 -0.323837  0.584374 -0.197406  1.759087  0.629100   \n",
       "2   -0.030556 -0.688181 -0.704432  0.479268 -0.132542  0.359878 -0.175965   \n",
       "3   -0.367174 -1.070520  0.641850  1.122959 -0.185011 -0.797308  0.118841   \n",
       "4    1.232648  0.173221 -0.874806 -1.385354 -0.189119 -0.777253 -0.881671   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "196  3.718558  0.997723  0.866509  0.138103 -0.189385  1.598474 -0.398698   \n",
       "197  1.148787  3.126753  0.704320 -0.850779 -0.188354 -0.877520 -0.466129   \n",
       "198 -0.253696 -0.499417 -1.687765 -1.604098 -0.185853 -0.611782 -0.823034   \n",
       "199  1.785866 -0.151980 -1.458628 -0.752409 -0.142349  0.099256  3.402072   \n",
       "200 -0.527846 -0.683398  1.553126 -0.274569 -0.134961 -1.508708 -0.622468   \n",
       "\n",
       "          7         8         9    ...       308       309       310  \\\n",
       "0    0.938434  0.525521  2.816893  ...  0.033111  0.666830 -0.118487   \n",
       "1   -0.790662 -0.589127 -0.553297  ...  0.330024 -1.159163  0.098005   \n",
       "2   -0.763096 -0.345673 -0.487867  ... -0.181768  0.579791 -0.750139   \n",
       "3   -0.390388 -0.116845 -0.775500  ...  1.175490  0.297293  0.437503   \n",
       "4   -0.174323  0.404659  0.026848  ...  0.779187  1.002412  1.054814   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "196 -0.961675  0.310080 -0.527057  ...  2.506972 -0.793247  0.371496   \n",
       "197 -1.056368 -0.470575 -0.630115  ...  0.099828 -0.174767  2.539953   \n",
       "198  1.076369 -0.627674 -0.750890  ...  0.197280  0.874318 -1.662648   \n",
       "199 -0.845676 -0.221001 -0.448069  ...  0.312156 -0.556186  1.618397   \n",
       "200 -0.300590 -0.534729  0.314695  ... -0.384887 -0.379786  0.039214   \n",
       "\n",
       "          311       312       313       314       315       316       317  \n",
       "0    0.474523  0.129464  0.793520  1.773637  2.455994 -0.847773 -0.406053  \n",
       "1   -0.723138 -0.854023  0.819247 -0.413771  0.838218  0.099293 -1.226462  \n",
       "2   -0.510297 -1.027384 -0.373156  5.566115 -0.158983  1.047293 -0.186207  \n",
       "3    0.532198 -0.469575 -0.373156 -0.408076 -0.807140  0.308259 -0.772790  \n",
       "4    1.483782 -0.231120 -0.373156  0.167400 -0.864338 -0.808003  0.351851  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "196 -0.123273 -1.173676 -0.373156 -0.192157  0.079920 -0.604231  1.217170  \n",
       "197  0.298970 -0.554954 -0.373156  0.142634  0.420574  0.083588 -0.318898  \n",
       "198  1.539526  0.619102 -0.373156 -0.386060 -0.268095 -1.203269  1.596772  \n",
       "199  0.370702 -0.597159 -0.373156  2.664853  0.119933  0.028534  0.216743  \n",
       "200 -0.367299 -0.385471 -0.373156  0.143448 -0.646715 -0.808854 -0.438916  \n",
       "\n",
       "[201 rows x 318 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "X_TRAIN= pd.DataFrame(scaler.fit_transform(x_train))\n",
    "\n",
    "X_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03a778fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_VALID=scaler.transform(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c346c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.19777128,  0.36515862, -1.25864736, ..., -0.78000326,\n",
       "        -1.51222763, -0.75122637],\n",
       "       [-0.30800808, -0.90897046, -0.59800395, ..., -0.54340311,\n",
       "        -0.51285613, -0.45719206],\n",
       "       [-0.47588434,  0.20752326, -0.35367825, ..., -1.17564204,\n",
       "        -0.75336981, -0.35333394],\n",
       "       ...,\n",
       "       [-0.46428028, -0.27649353,  1.58538629, ...,  0.00184106,\n",
       "         0.58803395, -0.59498043],\n",
       "       [-0.53043093, -0.81958104, -1.17704642, ..., -0.9728571 ,\n",
       "         0.2645351 ,  0.48173781],\n",
       "       [-0.45727734,  0.78653205, -0.73213448, ...,  0.0970342 ,\n",
       "        -0.08337097,  0.27787636]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_VALID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d9c8b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier_list = [  MLPClassifier(random_state=1),GradientBoostingClassifier(random_state=1)]\n",
    "def calc_metrics(cf_matrix):\n",
    "  tn = cf_matrix[0]\n",
    "  fp = cf_matrix[1]\n",
    "  fn = cf_matrix[2]\n",
    "  tp = cf_matrix[3]\n",
    "  if (((tp+fn)==0)|((tn+fp)==0)|((tp+fp)==0)|((tn+fp)==0)|((tn+fn)==0)):\n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = 0\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = 0\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1\n",
    "  else: \n",
    "    sens = tp/(tp+fn)\n",
    "    spec = tn/(tn+fp)\n",
    "    prec = tp/(tp+fp)\n",
    "    acc = (tp+tn)/(tp+tn+fn+fp)\n",
    "    mcc = ((tp*tn)-(fp*fn))/(((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))**0.5)\n",
    "    f1 = tp/(tp+(0.5*(fp+fn)))\n",
    "    return tp,fp,fn,tn,sens,spec,prec,acc,mcc,f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b32e8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier_list = [  MLPClassifier(random_state=1),GradientBoostingClassifier(random_state=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d51e05a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.6</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.524762</td>\n",
       "      <td>0.542548</td>\n",
       "      <td>0.542073</td>\n",
       "      <td>0.085996</td>\n",
       "      <td>0.547716</td>\n",
       "      <td>0.601643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.143964</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.666149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.662381</td>\n",
       "      <td>0.611503</td>\n",
       "      <td>0.601463</td>\n",
       "      <td>0.203891</td>\n",
       "      <td>0.572758</td>\n",
       "      <td>0.615762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.244932</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.631988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TP    FP    FN    TN      SENS      SPEC      PREC       ACC       MCC  \\\n",
       "0  11.2   9.6   8.8  10.6  0.560000  0.524762  0.542548  0.542073  0.085996   \n",
       "1  15.0   9.0  13.0  14.0  0.535714  0.608696  0.625000  0.568627  0.143964   \n",
       "2  10.8   6.8   9.2  13.4  0.540000  0.662381  0.611503  0.601463  0.203891   \n",
       "3  19.0  10.0   9.0  13.0  0.678571  0.565217  0.655172  0.627451  0.244932   \n",
       "\n",
       "         F1       AUC  \n",
       "0  0.547716  0.601643  \n",
       "1  0.576923  0.666149  \n",
       "2  0.572758  0.615762  \n",
       "3  0.666667  0.631988  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150,500,1000,1500,2000, 3000,4000,5000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,42]\n",
    "}\n",
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = GradientBoostingClassifier(random_state=1)\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(X_TRAIN, y_train):\n",
    "        train_x = X_TRAIN.iloc[train,:]\n",
    "        test_x = X_TRAIN.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(X_VALID)[:,1]\n",
    "    predict_label_y = clf.predict(X_VALID)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8eaf7ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'learning_rate': 0.5, 'max_depth': 3, 'n_estimators': 150, 'random_state': 42}\n",
      "AUROC on test data:  0.610248447204969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150,500,1000,1500,2000, 3000,4000,5000],\n",
    "    'learning_rate': [0.1, 0.5, 1.0],\n",
    "    'max_depth': [1, 3, 5, 10,20,50,100],\n",
    "    'random_state': [1,2,42]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "# Create a GridSearchCV object and fit it to the training data\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_TRAIN, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred_proba = best_clf.predict_proba(X_VALID)[:, 1]  # predicted probabilities for the positive class\n",
    "auroc = roc_auc_score(y_valid, y_pred_proba)\n",
    "print(\"AUROC on test data: \", auroc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "351ec1ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m aa\u001b[38;5;241m=\u001b[39m(\u001b[43mpredict_x\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_x' is not defined"
     ]
    }
   ],
   "source": [
    "aa=(predict_x>0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e491e946",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43maa\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "734c384d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m to_upload \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43maa\u001b[49m[:,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      2\u001b[0m cc \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1000\u001b[39m\u001b[38;5;241m+\u001b[39mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(test))]\n\u001b[1;32m      3\u001b[0m dd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(cc),pd\u001b[38;5;241m.\u001b[39mDataFrame(to_upload)],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aa' is not defined"
     ]
    }
   ],
   "source": [
    "to_upload = pd.DataFrame(aa[:,1])\n",
    "cc = [1000+i+1 for i in range(len(test))]\n",
    "dd = pd.concat([pd.DataFrame(cc),pd.DataFrame(to_upload)],axis=1)\n",
    "dd.columns = ['ID','Labels']\n",
    "dd.to_csv(\"7_run.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7faa5046",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.to_csv(\"first_run.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e362dbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACAN</th>\n",
       "      <th>AGER</th>\n",
       "      <th>ALPK1</th>\n",
       "      <th>ANKRD17</th>\n",
       "      <th>APOB</th>\n",
       "      <th>APPL1</th>\n",
       "      <th>APPL2</th>\n",
       "      <th>ARRB2</th>\n",
       "      <th>ASGR1</th>\n",
       "      <th>ASGR2</th>\n",
       "      <th>...</th>\n",
       "      <th>UBE2N</th>\n",
       "      <th>UBE2V1</th>\n",
       "      <th>UBQLN1</th>\n",
       "      <th>UFD1</th>\n",
       "      <th>UNC93B1</th>\n",
       "      <th>USP17L2</th>\n",
       "      <th>VCAN</th>\n",
       "      <th>WDFY1</th>\n",
       "      <th>XIAP</th>\n",
       "      <th>ZCCHC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44.1211</td>\n",
       "      <td>76.6643</td>\n",
       "      <td>1040.4443</td>\n",
       "      <td>1981.6944</td>\n",
       "      <td>0.6258</td>\n",
       "      <td>1356.1762</td>\n",
       "      <td>519.1270</td>\n",
       "      <td>1425.9563</td>\n",
       "      <td>33.7949</td>\n",
       "      <td>32.8561</td>\n",
       "      <td>...</td>\n",
       "      <td>2187.9058</td>\n",
       "      <td>3674.0734</td>\n",
       "      <td>2921.6929</td>\n",
       "      <td>1793.6228</td>\n",
       "      <td>1523.5860</td>\n",
       "      <td>0.3129</td>\n",
       "      <td>5315.4971</td>\n",
       "      <td>2514.5897</td>\n",
       "      <td>921.5364</td>\n",
       "      <td>564.4997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.1116</td>\n",
       "      <td>24.9440</td>\n",
       "      <td>384.7138</td>\n",
       "      <td>2125.0400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1839.7825</td>\n",
       "      <td>1204.9888</td>\n",
       "      <td>554.8449</td>\n",
       "      <td>3.8375</td>\n",
       "      <td>2.8782</td>\n",
       "      <td>...</td>\n",
       "      <td>2344.0998</td>\n",
       "      <td>1727.8414</td>\n",
       "      <td>3106.4918</td>\n",
       "      <td>1180.0352</td>\n",
       "      <td>554.8449</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>469.7793</td>\n",
       "      <td>1625.8395</td>\n",
       "      <td>1488.3275</td>\n",
       "      <td>316.2776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.6118</td>\n",
       "      <td>46.2410</td>\n",
       "      <td>289.7137</td>\n",
       "      <td>2054.7342</td>\n",
       "      <td>3.1456</td>\n",
       "      <td>1212.6455</td>\n",
       "      <td>833.5955</td>\n",
       "      <td>568.7323</td>\n",
       "      <td>10.3806</td>\n",
       "      <td>3.4602</td>\n",
       "      <td>...</td>\n",
       "      <td>2074.8663</td>\n",
       "      <td>3581.3023</td>\n",
       "      <td>2382.5102</td>\n",
       "      <td>1289.0783</td>\n",
       "      <td>384.0830</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>13716.8921</td>\n",
       "      <td>1078.0120</td>\n",
       "      <td>2055.6779</td>\n",
       "      <td>631.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.5306</td>\n",
       "      <td>20.7384</td>\n",
       "      <td>625.7589</td>\n",
       "      <td>2485.3028</td>\n",
       "      <td>0.6011</td>\n",
       "      <td>693.9853</td>\n",
       "      <td>969.5957</td>\n",
       "      <td>756.5010</td>\n",
       "      <td>16.5306</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>...</td>\n",
       "      <td>2788.8650</td>\n",
       "      <td>3280.2029</td>\n",
       "      <td>3396.2899</td>\n",
       "      <td>1823.1705</td>\n",
       "      <td>933.5289</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>482.3934</td>\n",
       "      <td>721.9370</td>\n",
       "      <td>1613.3880</td>\n",
       "      <td>453.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.7428</td>\n",
       "      <td>103.6977</td>\n",
       "      <td>247.1865</td>\n",
       "      <td>807.4759</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>702.9743</td>\n",
       "      <td>508.0386</td>\n",
       "      <td>865.3537</td>\n",
       "      <td>30.5466</td>\n",
       "      <td>8.0386</td>\n",
       "      <td>...</td>\n",
       "      <td>2580.3859</td>\n",
       "      <td>4031.7524</td>\n",
       "      <td>3923.2315</td>\n",
       "      <td>2310.6873</td>\n",
       "      <td>1168.4084</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1757.2347</td>\n",
       "      <td>690.5145</td>\n",
       "      <td>945.3376</td>\n",
       "      <td>793.8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>369.5060</td>\n",
       "      <td>158.6931</td>\n",
       "      <td>681.8359</td>\n",
       "      <td>1826.5266</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>1767.7946</td>\n",
       "      <td>730.8440</td>\n",
       "      <td>468.6892</td>\n",
       "      <td>28.0047</td>\n",
       "      <td>3.1116</td>\n",
       "      <td>...</td>\n",
       "      <td>3489.3038</td>\n",
       "      <td>2117.8530</td>\n",
       "      <td>3339.9455</td>\n",
       "      <td>1487.3590</td>\n",
       "      <td>239.9844</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>960.7157</td>\n",
       "      <td>1209.2571</td>\n",
       "      <td>1067.2890</td>\n",
       "      <td>1055.6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>147.4978</td>\n",
       "      <td>300.7024</td>\n",
       "      <td>641.3521</td>\n",
       "      <td>1165.0571</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>658.0334</td>\n",
       "      <td>699.7366</td>\n",
       "      <td>420.9833</td>\n",
       "      <td>7.0237</td>\n",
       "      <td>2.1949</td>\n",
       "      <td>...</td>\n",
       "      <td>2223.0026</td>\n",
       "      <td>2777.0588</td>\n",
       "      <td>5190.9570</td>\n",
       "      <td>1703.6831</td>\n",
       "      <td>849.4293</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1702.3705</td>\n",
       "      <td>1396.4004</td>\n",
       "      <td>1478.9289</td>\n",
       "      <td>590.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>26.3342</td>\n",
       "      <td>58.8318</td>\n",
       "      <td>44.2639</td>\n",
       "      <td>661.1570</td>\n",
       "      <td>0.5603</td>\n",
       "      <td>777.1397</td>\n",
       "      <td>535.0889</td>\n",
       "      <td>1495.4475</td>\n",
       "      <td>2.8015</td>\n",
       "      <td>1.1206</td>\n",
       "      <td>...</td>\n",
       "      <td>2274.2681</td>\n",
       "      <td>3895.2234</td>\n",
       "      <td>1603.5859</td>\n",
       "      <td>2339.2464</td>\n",
       "      <td>2005.8832</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>531.1668</td>\n",
       "      <td>1018.0698</td>\n",
       "      <td>708.7827</td>\n",
       "      <td>1170.4721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>202.5365</td>\n",
       "      <td>82.0063</td>\n",
       "      <td>101.4589</td>\n",
       "      <td>1230.8573</td>\n",
       "      <td>2.6700</td>\n",
       "      <td>1095.8329</td>\n",
       "      <td>2484.2186</td>\n",
       "      <td>527.1288</td>\n",
       "      <td>13.7313</td>\n",
       "      <td>3.8142</td>\n",
       "      <td>...</td>\n",
       "      <td>2334.7001</td>\n",
       "      <td>2370.5235</td>\n",
       "      <td>4404.3101</td>\n",
       "      <td>1740.4329</td>\n",
       "      <td>807.8573</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7289.7874</td>\n",
       "      <td>1231.2387</td>\n",
       "      <td>1445.9807</td>\n",
       "      <td>752.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2.6498</td>\n",
       "      <td>46.5600</td>\n",
       "      <td>853.2223</td>\n",
       "      <td>1550.4874</td>\n",
       "      <td>3.0283</td>\n",
       "      <td>375.1301</td>\n",
       "      <td>627.6143</td>\n",
       "      <td>801.7413</td>\n",
       "      <td>5.2995</td>\n",
       "      <td>10.5990</td>\n",
       "      <td>...</td>\n",
       "      <td>1968.0136</td>\n",
       "      <td>2558.5388</td>\n",
       "      <td>3056.3074</td>\n",
       "      <td>1362.3394</td>\n",
       "      <td>1016.3717</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1704.1734</td>\n",
       "      <td>810.0691</td>\n",
       "      <td>944.8282</td>\n",
       "      <td>554.5566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ACAN      AGER      ALPK1    ANKRD17    APOB      APPL1      APPL2  \\\n",
       "0     44.1211   76.6643  1040.4443  1981.6944  0.6258  1356.1762   519.1270   \n",
       "1     13.1116   24.9440   384.7138  2125.0400  0.0000  1839.7825  1204.9888   \n",
       "2     45.6118   46.2410   289.7137  2054.7342  3.1456  1212.6455   833.5955   \n",
       "3     16.5306   20.7384   625.7589  2485.3028  0.6011   693.9853   969.5957   \n",
       "4    154.7428  103.6977   247.1865   807.4759  0.4019   702.9743   508.0386   \n",
       "..        ...       ...        ...        ...     ...        ...        ...   \n",
       "196  369.5060  158.6931   681.8359  1826.5266  0.3890  1767.7946   730.8440   \n",
       "197  147.4978  300.7024   641.3521  1165.0571  0.4390   658.0334   699.7366   \n",
       "198   26.3342   58.8318    44.2639   661.1570  0.5603   777.1397   535.0889   \n",
       "199  202.5365   82.0063   101.4589  1230.8573  2.6700  1095.8329  2484.2186   \n",
       "200    2.6498   46.5600   853.2223  1550.4874  3.0283   375.1301   627.6143   \n",
       "\n",
       "         ARRB2    ASGR1    ASGR2  ...      UBE2N     UBE2V1     UBQLN1  \\\n",
       "0    1425.9563  33.7949  32.8561  ...  2187.9058  3674.0734  2921.6929   \n",
       "1     554.8449   3.8375   2.8782  ...  2344.0998  1727.8414  3106.4918   \n",
       "2     568.7323  10.3806   3.4602  ...  2074.8663  3581.3023  2382.5102   \n",
       "3     756.5010  16.5306   0.9017  ...  2788.8650  3280.2029  3396.2899   \n",
       "4     865.3537  30.5466   8.0386  ...  2580.3859  4031.7524  3923.2315   \n",
       "..         ...      ...      ...  ...        ...        ...        ...   \n",
       "196   468.6892  28.0047   3.1116  ...  3489.3038  2117.8530  3339.9455   \n",
       "197   420.9833   7.0237   2.1949  ...  2223.0026  2777.0588  5190.9570   \n",
       "198  1495.4475   2.8015   1.1206  ...  2274.2681  3895.2234  1603.5859   \n",
       "199   527.1288  13.7313   3.8142  ...  2334.7001  2370.5235  4404.3101   \n",
       "200   801.7413   5.2995  10.5990  ...  1968.0136  2558.5388  3056.3074   \n",
       "\n",
       "          UFD1    UNC93B1  USP17L2        VCAN      WDFY1       XIAP  \\\n",
       "0    1793.6228  1523.5860   0.3129   5315.4971  2514.5897   921.5364   \n",
       "1    1180.0352   554.8449   0.3198    469.7793  1625.8395  1488.3275   \n",
       "2    1289.0783   384.0830   0.0000  13716.8921  1078.0120  2055.6779   \n",
       "3    1823.1705   933.5289   0.0000    482.3934   721.9370  1613.3880   \n",
       "4    2310.6873  1168.4084   0.0000   1757.2347   690.5145   945.3376   \n",
       "..         ...        ...      ...         ...        ...        ...   \n",
       "196  1487.3590   239.9844   0.0000    960.7157  1209.2571  1067.2890   \n",
       "197  1703.6831   849.4293   0.0000   1702.3705  1396.4004  1478.9289   \n",
       "198  2339.2464  2005.8832   0.0000    531.1668  1018.0698   708.7827   \n",
       "199  1740.4329   807.8573   0.0000   7289.7874  1231.2387  1445.9807   \n",
       "200  1362.3394  1016.3717   0.0000   1704.1734   810.0691   944.8282   \n",
       "\n",
       "        ZCCHC3  \n",
       "0     564.4997  \n",
       "1     316.2776  \n",
       "2     631.0160  \n",
       "3     453.5400  \n",
       "4     793.8103  \n",
       "..         ...  \n",
       "196  1055.6204  \n",
       "197   590.8692  \n",
       "198  1170.4721  \n",
       "199   752.9322  \n",
       "200   554.5566  \n",
       "\n",
       "[201 rows x 318 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d78baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature selection\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold #Import the library\n",
    "sel = VarianceThreshold(1.0) # This will remove all zero-variance features\n",
    "sf = sel.fit_transform(X_TRAIN) # The file will be saved in sf\n",
    "sc = X_TRAIN.columns[sel.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "x2=X_TRAIN[sc] #This will show the first few rows of selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c1a7efb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>27</th>\n",
       "      <th>33</th>\n",
       "      <th>...</th>\n",
       "      <th>281</th>\n",
       "      <th>294</th>\n",
       "      <th>296</th>\n",
       "      <th>300</th>\n",
       "      <th>301</th>\n",
       "      <th>302</th>\n",
       "      <th>307</th>\n",
       "      <th>309</th>\n",
       "      <th>310</th>\n",
       "      <th>313</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.184502</td>\n",
       "      <td>-0.857634</td>\n",
       "      <td>-0.170840</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>-0.607543</td>\n",
       "      <td>-0.206847</td>\n",
       "      <td>-0.199225</td>\n",
       "      <td>0.292715</td>\n",
       "      <td>0.550445</td>\n",
       "      <td>-0.115655</td>\n",
       "      <td>...</td>\n",
       "      <td>2.649880</td>\n",
       "      <td>-0.273092</td>\n",
       "      <td>-0.181720</td>\n",
       "      <td>-1.133675</td>\n",
       "      <td>-1.049067</td>\n",
       "      <td>-0.471426</td>\n",
       "      <td>0.197359</td>\n",
       "      <td>0.666830</td>\n",
       "      <td>-0.118487</td>\n",
       "      <td>0.793520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>0.629100</td>\n",
       "      <td>0.534005</td>\n",
       "      <td>-0.395742</td>\n",
       "      <td>0.419445</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.614487</td>\n",
       "      <td>0.100520</td>\n",
       "      <td>-0.668599</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374942</td>\n",
       "      <td>0.550822</td>\n",
       "      <td>-0.177140</td>\n",
       "      <td>-0.424790</td>\n",
       "      <td>1.736485</td>\n",
       "      <td>-0.624304</td>\n",
       "      <td>0.139293</td>\n",
       "      <td>-1.159163</td>\n",
       "      <td>0.098005</td>\n",
       "      <td>0.819247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.132542</td>\n",
       "      <td>-0.175965</td>\n",
       "      <td>3.491454</td>\n",
       "      <td>-0.574503</td>\n",
       "      <td>0.946171</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.553495</td>\n",
       "      <td>-0.452664</td>\n",
       "      <td>0.642981</td>\n",
       "      <td>-0.022741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138666</td>\n",
       "      <td>-0.311206</td>\n",
       "      <td>0.654508</td>\n",
       "      <td>0.808407</td>\n",
       "      <td>-1.150300</td>\n",
       "      <td>-0.571716</td>\n",
       "      <td>-0.914784</td>\n",
       "      <td>0.579791</td>\n",
       "      <td>-0.750139</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.185011</td>\n",
       "      <td>0.118841</td>\n",
       "      <td>0.322111</td>\n",
       "      <td>-0.316933</td>\n",
       "      <td>0.259556</td>\n",
       "      <td>-0.203760</td>\n",
       "      <td>-0.564971</td>\n",
       "      <td>-1.281413</td>\n",
       "      <td>-0.742744</td>\n",
       "      <td>-0.117467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445997</td>\n",
       "      <td>2.018679</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.289848</td>\n",
       "      <td>-0.971361</td>\n",
       "      <td>-0.163342</td>\n",
       "      <td>1.076859</td>\n",
       "      <td>0.297293</td>\n",
       "      <td>0.437503</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.189119</td>\n",
       "      <td>-0.881671</td>\n",
       "      <td>0.110554</td>\n",
       "      <td>-0.455843</td>\n",
       "      <td>0.136417</td>\n",
       "      <td>-0.198375</td>\n",
       "      <td>-0.648063</td>\n",
       "      <td>-0.956528</td>\n",
       "      <td>0.836261</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126578</td>\n",
       "      <td>0.402918</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.144329</td>\n",
       "      <td>-0.851919</td>\n",
       "      <td>0.216837</td>\n",
       "      <td>-0.571389</td>\n",
       "      <td>1.002412</td>\n",
       "      <td>1.054814</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.189385</td>\n",
       "      <td>-0.398698</td>\n",
       "      <td>-0.590785</td>\n",
       "      <td>-0.664764</td>\n",
       "      <td>-1.102614</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.022065</td>\n",
       "      <td>-0.430919</td>\n",
       "      <td>2.471779</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410573</td>\n",
       "      <td>-0.835133</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.080504</td>\n",
       "      <td>-1.354338</td>\n",
       "      <td>-0.470195</td>\n",
       "      <td>0.907172</td>\n",
       "      <td>-0.793247</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.188354</td>\n",
       "      <td>-0.466129</td>\n",
       "      <td>0.694122</td>\n",
       "      <td>0.085607</td>\n",
       "      <td>-0.149674</td>\n",
       "      <td>-0.206744</td>\n",
       "      <td>-0.520888</td>\n",
       "      <td>-0.106726</td>\n",
       "      <td>0.475260</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225202</td>\n",
       "      <td>-0.233339</td>\n",
       "      <td>2.815600</td>\n",
       "      <td>-0.936952</td>\n",
       "      <td>-0.062980</td>\n",
       "      <td>-0.466959</td>\n",
       "      <td>-1.218578</td>\n",
       "      <td>-0.174767</td>\n",
       "      <td>2.539953</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.185853</td>\n",
       "      <td>-0.823034</td>\n",
       "      <td>0.560087</td>\n",
       "      <td>-0.674450</td>\n",
       "      <td>-1.373242</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.808794</td>\n",
       "      <td>-2.079775</td>\n",
       "      <td>-0.409450</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.402557</td>\n",
       "      <td>-0.802722</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.605120</td>\n",
       "      <td>0.306691</td>\n",
       "      <td>-0.487064</td>\n",
       "      <td>-2.119008</td>\n",
       "      <td>0.874318</td>\n",
       "      <td>-1.662648</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.142349</td>\n",
       "      <td>3.402072</td>\n",
       "      <td>-0.184539</td>\n",
       "      <td>0.341866</td>\n",
       "      <td>-0.902556</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.106581</td>\n",
       "      <td>-0.478019</td>\n",
       "      <td>1.156297</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.251391</td>\n",
       "      <td>-0.141232</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.779416</td>\n",
       "      <td>2.578961</td>\n",
       "      <td>-0.408338</td>\n",
       "      <td>-1.456982</td>\n",
       "      <td>-0.556186</td>\n",
       "      <td>1.618397</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.134961</td>\n",
       "      <td>-0.622468</td>\n",
       "      <td>-1.303493</td>\n",
       "      <td>0.486543</td>\n",
       "      <td>0.059680</td>\n",
       "      <td>2.040736</td>\n",
       "      <td>0.134004</td>\n",
       "      <td>0.089079</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>-0.050226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193372</td>\n",
       "      <td>0.523372</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.716771</td>\n",
       "      <td>0.516144</td>\n",
       "      <td>0.213987</td>\n",
       "      <td>1.035542</td>\n",
       "      <td>-0.379786</td>\n",
       "      <td>0.039214</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          4         6         10        12        13        16        19   \\\n",
       "0   -0.184502 -0.857634 -0.170840  0.056357 -0.607543 -0.206847 -0.199225   \n",
       "1   -0.197406  0.629100  0.534005 -0.395742  0.419445 -0.206940 -0.614487   \n",
       "2   -0.132542 -0.175965  3.491454 -0.574503  0.946171 -0.206940 -0.553495   \n",
       "3   -0.185011  0.118841  0.322111 -0.316933  0.259556 -0.203760 -0.564971   \n",
       "4   -0.189119 -0.881671  0.110554 -0.455843  0.136417 -0.198375 -0.648063   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "196 -0.189385 -0.398698 -0.590785 -0.664764 -1.102614 -0.206940 -0.022065   \n",
       "197 -0.188354 -0.466129  0.694122  0.085607 -0.149674 -0.206744 -0.520888   \n",
       "198 -0.185853 -0.823034  0.560087 -0.674450 -1.373242 -0.206940 -0.808794   \n",
       "199 -0.142349  3.402072 -0.184539  0.341866 -0.902556 -0.206940 -0.106581   \n",
       "200 -0.134961 -0.622468 -1.303493  0.486543  0.059680  2.040736  0.134004   \n",
       "\n",
       "          20        27        33   ...       281       294       296  \\\n",
       "0    0.292715  0.550445 -0.115655  ...  2.649880 -0.273092 -0.181720   \n",
       "1    0.100520 -0.668599 -0.161744  ... -0.374942  0.550822 -0.177140   \n",
       "2   -0.452664  0.642981 -0.022741  ... -0.138666 -0.311206  0.654508   \n",
       "3   -1.281413 -0.742744 -0.117467  ... -0.445997  2.018679 -0.389400   \n",
       "4   -0.956528  0.836261 -0.161744  ... -0.126578  0.402918 -0.389400   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "196 -0.430919  2.471779 -0.161744  ... -0.410573 -0.835133 -0.389400   \n",
       "197 -0.106726  0.475260 -0.161744  ... -0.225202 -0.233339  2.815600   \n",
       "198 -2.079775 -0.409450 -0.161744  ... -0.402557 -0.802722 -0.389400   \n",
       "199 -0.478019  1.156297 -0.161744  ... -0.251391 -0.141232 -0.389400   \n",
       "200  0.089079  0.028396 -0.050226  ... -0.193372  0.523372 -0.389400   \n",
       "\n",
       "          300       301       302       307       309       310       313  \n",
       "0   -1.133675 -1.049067 -0.471426  0.197359  0.666830 -0.118487  0.793520  \n",
       "1   -0.424790  1.736485 -0.624304  0.139293 -1.159163  0.098005  0.819247  \n",
       "2    0.808407 -1.150300 -0.571716 -0.914784  0.579791 -0.750139 -0.373156  \n",
       "3   -0.289848 -0.971361 -0.163342  1.076859  0.297293  0.437503 -0.373156  \n",
       "4   -0.144329 -0.851919  0.216837 -0.571389  1.002412  1.054814 -0.373156  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "196  0.080504 -1.354338 -0.470195  0.907172 -0.793247  0.371496 -0.373156  \n",
       "197 -0.936952 -0.062980 -0.466959 -1.218578 -0.174767  2.539953 -0.373156  \n",
       "198  0.605120  0.306691 -0.487064 -2.119008  0.874318 -1.662648 -0.373156  \n",
       "199 -0.779416  2.578961 -0.408338 -1.456982 -0.556186  1.618397 -0.373156  \n",
       "200 -0.716771  0.516144  0.213987  1.035542 -0.379786  0.039214 -0.373156  \n",
       "\n",
       "[201 rows x 98 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c42532e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val= sel.transform(X_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42ff4c15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_val=pd.DataFrame(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdab916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-1.152949</td>\n",
       "      <td>-0.892383</td>\n",
       "      <td>0.407789</td>\n",
       "      <td>-1.112493</td>\n",
       "      <td>-0.183772</td>\n",
       "      <td>-0.981380</td>\n",
       "      <td>-1.468625</td>\n",
       "      <td>-0.345237</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284202</td>\n",
       "      <td>-1.410780</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-1.135510</td>\n",
       "      <td>-0.303629</td>\n",
       "      <td>10.998169</td>\n",
       "      <td>-0.070555</td>\n",
       "      <td>0.845148</td>\n",
       "      <td>-1.067224</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.525053</td>\n",
       "      <td>-0.289118</td>\n",
       "      <td>-0.136211</td>\n",
       "      <td>-0.708274</td>\n",
       "      <td>0.421234</td>\n",
       "      <td>-0.206912</td>\n",
       "      <td>1.169015</td>\n",
       "      <td>-0.057043</td>\n",
       "      <td>-0.158037</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.101916</td>\n",
       "      <td>0.981233</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-1.064894</td>\n",
       "      <td>-1.242841</td>\n",
       "      <td>0.057434</td>\n",
       "      <td>1.361961</td>\n",
       "      <td>0.319770</td>\n",
       "      <td>2.069493</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.571145</td>\n",
       "      <td>-0.777656</td>\n",
       "      <td>-0.736148</td>\n",
       "      <td>-1.065346</td>\n",
       "      <td>-0.206695</td>\n",
       "      <td>0.102180</td>\n",
       "      <td>-0.187399</td>\n",
       "      <td>0.100647</td>\n",
       "      <td>0.242685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.644850</td>\n",
       "      <td>-0.347716</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.706712</td>\n",
       "      <td>-0.465162</td>\n",
       "      <td>1.953518</td>\n",
       "      <td>-0.228148</td>\n",
       "      <td>-0.674436</td>\n",
       "      <td>-0.973728</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.071813</td>\n",
       "      <td>-0.468509</td>\n",
       "      <td>0.349780</td>\n",
       "      <td>-0.012869</td>\n",
       "      <td>-1.248619</td>\n",
       "      <td>-0.169377</td>\n",
       "      <td>-1.230521</td>\n",
       "      <td>-0.884092</td>\n",
       "      <td>15.632001</td>\n",
       "      <td>-0.003431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113438</td>\n",
       "      <td>-0.372181</td>\n",
       "      <td>1.750784</td>\n",
       "      <td>-0.154840</td>\n",
       "      <td>-0.872758</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>0.643646</td>\n",
       "      <td>0.422515</td>\n",
       "      <td>0.546828</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.554682</td>\n",
       "      <td>-1.301376</td>\n",
       "      <td>-0.485831</td>\n",
       "      <td>5.283663</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.484873</td>\n",
       "      <td>-1.110872</td>\n",
       "      <td>-0.142478</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.427940</td>\n",
       "      <td>-0.445768</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.773266</td>\n",
       "      <td>-0.019030</td>\n",
       "      <td>0.426392</td>\n",
       "      <td>1.398153</td>\n",
       "      <td>-0.913908</td>\n",
       "      <td>0.004746</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.155388</td>\n",
       "      <td>1.227182</td>\n",
       "      <td>-1.263649</td>\n",
       "      <td>3.807565</td>\n",
       "      <td>1.874043</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>0.115816</td>\n",
       "      <td>-0.954015</td>\n",
       "      <td>-0.176646</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231007</td>\n",
       "      <td>0.639378</td>\n",
       "      <td>2.991752</td>\n",
       "      <td>-0.604531</td>\n",
       "      <td>-0.326557</td>\n",
       "      <td>-0.186227</td>\n",
       "      <td>0.230351</td>\n",
       "      <td>-0.434106</td>\n",
       "      <td>-0.585346</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.542280</td>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-0.043602</td>\n",
       "      <td>0.312341</td>\n",
       "      <td>-0.206674</td>\n",
       "      <td>-0.688003</td>\n",
       "      <td>1.363689</td>\n",
       "      <td>0.897546</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.612690</td>\n",
       "      <td>0.257477</td>\n",
       "      <td>1.337947</td>\n",
       "      <td>0.049874</td>\n",
       "      <td>-0.056159</td>\n",
       "      <td>-0.471635</td>\n",
       "      <td>0.287637</td>\n",
       "      <td>-0.272107</td>\n",
       "      <td>2.736600</td>\n",
       "      <td>2.052665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.188927</td>\n",
       "      <td>-0.455219</td>\n",
       "      <td>-0.514563</td>\n",
       "      <td>0.214680</td>\n",
       "      <td>0.109264</td>\n",
       "      <td>-0.204704</td>\n",
       "      <td>0.031033</td>\n",
       "      <td>1.051813</td>\n",
       "      <td>-0.174715</td>\n",
       "      <td>-0.101176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666046</td>\n",
       "      <td>-0.714006</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.310410</td>\n",
       "      <td>-0.260173</td>\n",
       "      <td>-0.426441</td>\n",
       "      <td>-0.318067</td>\n",
       "      <td>-0.463256</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.188381</td>\n",
       "      <td>-0.493381</td>\n",
       "      <td>1.279063</td>\n",
       "      <td>-0.687950</td>\n",
       "      <td>-0.528460</td>\n",
       "      <td>-0.206875</td>\n",
       "      <td>0.096217</td>\n",
       "      <td>-1.225756</td>\n",
       "      <td>2.041290</td>\n",
       "      <td>0.031670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184560</td>\n",
       "      <td>0.916197</td>\n",
       "      <td>-0.098887</td>\n",
       "      <td>0.515465</td>\n",
       "      <td>0.686147</td>\n",
       "      <td>-0.162070</td>\n",
       "      <td>-1.298626</td>\n",
       "      <td>3.364564</td>\n",
       "      <td>-0.442716</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.056241</td>\n",
       "      <td>-0.309892</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>4.685989</td>\n",
       "      <td>-0.206920</td>\n",
       "      <td>-0.543887</td>\n",
       "      <td>0.980489</td>\n",
       "      <td>-0.141224</td>\n",
       "      <td>-0.120501</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135252</td>\n",
       "      <td>-0.040952</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.064767</td>\n",
       "      <td>0.706438</td>\n",
       "      <td>-0.371978</td>\n",
       "      <td>1.750467</td>\n",
       "      <td>-0.585226</td>\n",
       "      <td>0.928558</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.082919</td>\n",
       "      <td>-0.487022</td>\n",
       "      <td>-0.243317</td>\n",
       "      <td>3.713932</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.375906</td>\n",
       "      <td>1.187749</td>\n",
       "      <td>-0.199322</td>\n",
       "      <td>-0.099939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345640</td>\n",
       "      <td>1.023961</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.177260</td>\n",
       "      <td>0.108126</td>\n",
       "      <td>-0.467255</td>\n",
       "      <td>1.083701</td>\n",
       "      <td>-0.346616</td>\n",
       "      <td>0.249563</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.775363</td>\n",
       "      <td>-0.957330</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>-0.358645</td>\n",
       "      <td>-0.202307</td>\n",
       "      <td>0.309196</td>\n",
       "      <td>-1.157995</td>\n",
       "      <td>0.185083</td>\n",
       "      <td>-0.098569</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396972</td>\n",
       "      <td>-0.126220</td>\n",
       "      <td>0.179878</td>\n",
       "      <td>-0.901076</td>\n",
       "      <td>0.529862</td>\n",
       "      <td>0.113559</td>\n",
       "      <td>-0.640480</td>\n",
       "      <td>-0.420425</td>\n",
       "      <td>0.370950</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.788077</td>\n",
       "      <td>-0.108285</td>\n",
       "      <td>-0.683043</td>\n",
       "      <td>1.326500</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>1.366383</td>\n",
       "      <td>0.648637</td>\n",
       "      <td>-0.543128</td>\n",
       "      <td>-0.033877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549263</td>\n",
       "      <td>0.245194</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.508508</td>\n",
       "      <td>-0.619410</td>\n",
       "      <td>-0.045688</td>\n",
       "      <td>1.378305</td>\n",
       "      <td>-0.375478</td>\n",
       "      <td>-0.971814</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.057665</td>\n",
       "      <td>1.636301</td>\n",
       "      <td>-0.223654</td>\n",
       "      <td>-0.223119</td>\n",
       "      <td>0.293026</td>\n",
       "      <td>0.206548</td>\n",
       "      <td>-0.962624</td>\n",
       "      <td>0.638227</td>\n",
       "      <td>-0.833195</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.419911</td>\n",
       "      <td>0.265130</td>\n",
       "      <td>0.172842</td>\n",
       "      <td>4.764838</td>\n",
       "      <td>-0.556687</td>\n",
       "      <td>-0.618751</td>\n",
       "      <td>-0.658737</td>\n",
       "      <td>-0.705549</td>\n",
       "      <td>-1.135233</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.892504</td>\n",
       "      <td>5.093768</td>\n",
       "      <td>0.121310</td>\n",
       "      <td>-0.230621</td>\n",
       "      <td>-0.028129</td>\n",
       "      <td>-0.206207</td>\n",
       "      <td>-0.101754</td>\n",
       "      <td>0.269929</td>\n",
       "      <td>0.664296</td>\n",
       "      <td>0.200514</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504311</td>\n",
       "      <td>0.579815</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.791721</td>\n",
       "      <td>-1.373242</td>\n",
       "      <td>-0.154023</td>\n",
       "      <td>0.308769</td>\n",
       "      <td>-0.754756</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>1.026031</td>\n",
       "      <td>0.655874</td>\n",
       "      <td>0.699575</td>\n",
       "      <td>4.219049</td>\n",
       "      <td>-0.129809</td>\n",
       "      <td>-0.544149</td>\n",
       "      <td>-0.530409</td>\n",
       "      <td>-0.535182</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358002</td>\n",
       "      <td>-0.910863</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>1.947498</td>\n",
       "      <td>-1.083991</td>\n",
       "      <td>-0.339996</td>\n",
       "      <td>0.141742</td>\n",
       "      <td>0.207014</td>\n",
       "      <td>-1.402438</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.972207</td>\n",
       "      <td>-1.484722</td>\n",
       "      <td>1.891841</td>\n",
       "      <td>0.579962</td>\n",
       "      <td>-0.196931</td>\n",
       "      <td>-0.455378</td>\n",
       "      <td>-0.975824</td>\n",
       "      <td>-0.376939</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169920</td>\n",
       "      <td>-0.869151</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.158307</td>\n",
       "      <td>-0.568464</td>\n",
       "      <td>3.810881</td>\n",
       "      <td>-0.014879</td>\n",
       "      <td>0.861589</td>\n",
       "      <td>-1.825590</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>0.378201</td>\n",
       "      <td>0.947177</td>\n",
       "      <td>-0.436224</td>\n",
       "      <td>0.390505</td>\n",
       "      <td>-0.206922</td>\n",
       "      <td>-0.589436</td>\n",
       "      <td>-0.048283</td>\n",
       "      <td>-0.506207</td>\n",
       "      <td>-0.125273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077038</td>\n",
       "      <td>1.089771</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.217744</td>\n",
       "      <td>0.752242</td>\n",
       "      <td>-0.196899</td>\n",
       "      <td>-1.577878</td>\n",
       "      <td>0.297272</td>\n",
       "      <td>0.950882</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.090229</td>\n",
       "      <td>-0.025331</td>\n",
       "      <td>-0.694131</td>\n",
       "      <td>0.090559</td>\n",
       "      <td>-0.776531</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.684280</td>\n",
       "      <td>1.065592</td>\n",
       "      <td>0.385908</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110133</td>\n",
       "      <td>-0.635497</td>\n",
       "      <td>-0.101940</td>\n",
       "      <td>-1.033944</td>\n",
       "      <td>-1.245750</td>\n",
       "      <td>-0.242662</td>\n",
       "      <td>-0.881734</td>\n",
       "      <td>0.265528</td>\n",
       "      <td>0.318674</td>\n",
       "      <td>1.241697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.191717</td>\n",
       "      <td>0.696165</td>\n",
       "      <td>-0.566189</td>\n",
       "      <td>-0.098065</td>\n",
       "      <td>2.912579</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.314335</td>\n",
       "      <td>1.007171</td>\n",
       "      <td>-0.158989</td>\n",
       "      <td>-0.080451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142830</td>\n",
       "      <td>0.943173</td>\n",
       "      <td>0.343221</td>\n",
       "      <td>0.797598</td>\n",
       "      <td>-0.189391</td>\n",
       "      <td>-0.391425</td>\n",
       "      <td>1.063183</td>\n",
       "      <td>-0.115755</td>\n",
       "      <td>1.599577</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.185949</td>\n",
       "      <td>0.272660</td>\n",
       "      <td>2.126326</td>\n",
       "      <td>-0.674972</td>\n",
       "      <td>-0.311515</td>\n",
       "      <td>-0.206195</td>\n",
       "      <td>0.397774</td>\n",
       "      <td>-0.549987</td>\n",
       "      <td>-0.197009</td>\n",
       "      <td>0.042835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076638</td>\n",
       "      <td>0.190350</td>\n",
       "      <td>0.901149</td>\n",
       "      <td>1.652483</td>\n",
       "      <td>-0.579729</td>\n",
       "      <td>-0.271578</td>\n",
       "      <td>-1.108678</td>\n",
       "      <td>0.946713</td>\n",
       "      <td>-1.155294</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.181539</td>\n",
       "      <td>-0.776908</td>\n",
       "      <td>0.054722</td>\n",
       "      <td>0.619635</td>\n",
       "      <td>-0.085953</td>\n",
       "      <td>1.221667</td>\n",
       "      <td>-1.100209</td>\n",
       "      <td>-0.529115</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386839</td>\n",
       "      <td>-1.398304</td>\n",
       "      <td>2.675155</td>\n",
       "      <td>0.397213</td>\n",
       "      <td>-0.456293</td>\n",
       "      <td>-0.461792</td>\n",
       "      <td>-1.215308</td>\n",
       "      <td>-0.090502</td>\n",
       "      <td>-0.521223</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.180384</td>\n",
       "      <td>-0.112076</td>\n",
       "      <td>-0.959738</td>\n",
       "      <td>0.445562</td>\n",
       "      <td>-0.966646</td>\n",
       "      <td>-0.191316</td>\n",
       "      <td>-0.563976</td>\n",
       "      <td>0.068553</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342878</td>\n",
       "      <td>0.127456</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.692614</td>\n",
       "      <td>0.709436</td>\n",
       "      <td>-0.255422</td>\n",
       "      <td>0.150369</td>\n",
       "      <td>0.458735</td>\n",
       "      <td>1.149100</td>\n",
       "      <td>1.166006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.189507</td>\n",
       "      <td>-0.630834</td>\n",
       "      <td>0.107317</td>\n",
       "      <td>0.684236</td>\n",
       "      <td>2.228339</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>0.565500</td>\n",
       "      <td>1.008931</td>\n",
       "      <td>-0.589119</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071072</td>\n",
       "      <td>-0.444733</td>\n",
       "      <td>0.882100</td>\n",
       "      <td>-0.180800</td>\n",
       "      <td>-1.151414</td>\n",
       "      <td>-0.058924</td>\n",
       "      <td>-0.225916</td>\n",
       "      <td>-0.338011</td>\n",
       "      <td>-0.112032</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.174668</td>\n",
       "      <td>1.398851</td>\n",
       "      <td>1.576386</td>\n",
       "      <td>-0.624840</td>\n",
       "      <td>-0.909349</td>\n",
       "      <td>-0.189027</td>\n",
       "      <td>0.038566</td>\n",
       "      <td>-0.007329</td>\n",
       "      <td>-0.203308</td>\n",
       "      <td>-0.121134</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.226987</td>\n",
       "      <td>1.862962</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-1.135664</td>\n",
       "      <td>0.939571</td>\n",
       "      <td>-0.464304</td>\n",
       "      <td>-0.173033</td>\n",
       "      <td>0.046406</td>\n",
       "      <td>-0.660744</td>\n",
       "      <td>0.654817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>0.378201</td>\n",
       "      <td>0.947177</td>\n",
       "      <td>-0.436224</td>\n",
       "      <td>0.390505</td>\n",
       "      <td>-0.206922</td>\n",
       "      <td>-0.589436</td>\n",
       "      <td>-0.048283</td>\n",
       "      <td>-0.506207</td>\n",
       "      <td>-0.125273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077038</td>\n",
       "      <td>1.089771</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.217744</td>\n",
       "      <td>0.752242</td>\n",
       "      <td>-0.196899</td>\n",
       "      <td>-1.577878</td>\n",
       "      <td>0.297272</td>\n",
       "      <td>0.950882</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.423606</td>\n",
       "      <td>0.754155</td>\n",
       "      <td>0.163767</td>\n",
       "      <td>-1.381171</td>\n",
       "      <td>-0.186300</td>\n",
       "      <td>-0.261924</td>\n",
       "      <td>0.402806</td>\n",
       "      <td>-0.301895</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028618</td>\n",
       "      <td>-0.751451</td>\n",
       "      <td>1.341730</td>\n",
       "      <td>1.723305</td>\n",
       "      <td>-0.461954</td>\n",
       "      <td>-0.111834</td>\n",
       "      <td>-1.397333</td>\n",
       "      <td>-0.070824</td>\n",
       "      <td>0.431583</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.533572</td>\n",
       "      <td>0.636675</td>\n",
       "      <td>-0.628389</td>\n",
       "      <td>-1.081280</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>0.403653</td>\n",
       "      <td>-0.888978</td>\n",
       "      <td>-0.206936</td>\n",
       "      <td>-0.053644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884230</td>\n",
       "      <td>0.495166</td>\n",
       "      <td>0.097709</td>\n",
       "      <td>-0.217577</td>\n",
       "      <td>-0.899280</td>\n",
       "      <td>1.542499</td>\n",
       "      <td>1.420682</td>\n",
       "      <td>-0.143602</td>\n",
       "      <td>0.528691</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.087447</td>\n",
       "      <td>0.723271</td>\n",
       "      <td>0.278285</td>\n",
       "      <td>0.173416</td>\n",
       "      <td>0.033805</td>\n",
       "      <td>-0.202569</td>\n",
       "      <td>-1.359015</td>\n",
       "      <td>1.046378</td>\n",
       "      <td>0.906244</td>\n",
       "      <td>-0.115537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244859</td>\n",
       "      <td>0.460015</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>1.242272</td>\n",
       "      <td>-1.387882</td>\n",
       "      <td>-0.565250</td>\n",
       "      <td>0.179404</td>\n",
       "      <td>-0.364372</td>\n",
       "      <td>-0.828205</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.163114</td>\n",
       "      <td>1.714387</td>\n",
       "      <td>-1.235911</td>\n",
       "      <td>-0.390258</td>\n",
       "      <td>0.467395</td>\n",
       "      <td>-0.027505</td>\n",
       "      <td>-0.975821</td>\n",
       "      <td>-0.244783</td>\n",
       "      <td>-0.326672</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.374046</td>\n",
       "      <td>-0.930736</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.973690</td>\n",
       "      <td>-0.293373</td>\n",
       "      <td>0.365655</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>1.019428</td>\n",
       "      <td>-1.829456</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.179800</td>\n",
       "      <td>-0.675387</td>\n",
       "      <td>-0.161026</td>\n",
       "      <td>-0.250405</td>\n",
       "      <td>-1.159355</td>\n",
       "      <td>-0.192276</td>\n",
       "      <td>0.778843</td>\n",
       "      <td>-0.680546</td>\n",
       "      <td>0.478560</td>\n",
       "      <td>-0.098863</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298717</td>\n",
       "      <td>-0.041181</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>1.425854</td>\n",
       "      <td>0.557112</td>\n",
       "      <td>-0.330954</td>\n",
       "      <td>-0.471067</td>\n",
       "      <td>-0.211074</td>\n",
       "      <td>-0.145525</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.087024</td>\n",
       "      <td>-0.787774</td>\n",
       "      <td>0.952674</td>\n",
       "      <td>-0.097588</td>\n",
       "      <td>2.531243</td>\n",
       "      <td>-0.201281</td>\n",
       "      <td>-0.031597</td>\n",
       "      <td>-0.432273</td>\n",
       "      <td>-0.448440</td>\n",
       "      <td>-0.013903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248387</td>\n",
       "      <td>-1.270679</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>2.099330</td>\n",
       "      <td>-0.346175</td>\n",
       "      <td>-0.034327</td>\n",
       "      <td>1.051292</td>\n",
       "      <td>-0.650822</td>\n",
       "      <td>-1.879435</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.176095</td>\n",
       "      <td>-0.257900</td>\n",
       "      <td>-0.146450</td>\n",
       "      <td>-0.710858</td>\n",
       "      <td>-0.233679</td>\n",
       "      <td>-0.187097</td>\n",
       "      <td>0.506380</td>\n",
       "      <td>-0.116203</td>\n",
       "      <td>0.654617</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213123</td>\n",
       "      <td>1.421938</td>\n",
       "      <td>-0.160746</td>\n",
       "      <td>0.714260</td>\n",
       "      <td>-0.286305</td>\n",
       "      <td>-0.345904</td>\n",
       "      <td>-0.701443</td>\n",
       "      <td>2.567135</td>\n",
       "      <td>0.441304</td>\n",
       "      <td>0.911344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.447306</td>\n",
       "      <td>-0.120772</td>\n",
       "      <td>-0.869098</td>\n",
       "      <td>-0.390045</td>\n",
       "      <td>-0.714890</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.010379</td>\n",
       "      <td>0.491797</td>\n",
       "      <td>-0.622245</td>\n",
       "      <td>-0.015538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278448</td>\n",
       "      <td>0.532293</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-1.583679</td>\n",
       "      <td>-0.091866</td>\n",
       "      <td>-0.275838</td>\n",
       "      <td>2.799386</td>\n",
       "      <td>-0.333413</td>\n",
       "      <td>0.119760</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.182442</td>\n",
       "      <td>-0.906412</td>\n",
       "      <td>2.600997</td>\n",
       "      <td>-0.132377</td>\n",
       "      <td>1.415686</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.482477</td>\n",
       "      <td>-0.375368</td>\n",
       "      <td>0.067966</td>\n",
       "      <td>0.657763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>-0.254941</td>\n",
       "      <td>0.092266</td>\n",
       "      <td>-0.371777</td>\n",
       "      <td>0.168890</td>\n",
       "      <td>-0.248581</td>\n",
       "      <td>0.835665</td>\n",
       "      <td>0.902398</td>\n",
       "      <td>0.398696</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.151119</td>\n",
       "      <td>-0.269225</td>\n",
       "      <td>0.608706</td>\n",
       "      <td>-0.637279</td>\n",
       "      <td>-1.151401</td>\n",
       "      <td>-0.173922</td>\n",
       "      <td>-0.422851</td>\n",
       "      <td>1.540069</td>\n",
       "      <td>-0.214420</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243530</td>\n",
       "      <td>0.462879</td>\n",
       "      <td>0.504506</td>\n",
       "      <td>0.225061</td>\n",
       "      <td>-0.563461</td>\n",
       "      <td>-0.602541</td>\n",
       "      <td>-1.970501</td>\n",
       "      <td>-0.202102</td>\n",
       "      <td>-0.687050</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.827841</td>\n",
       "      <td>-0.263335</td>\n",
       "      <td>0.654868</td>\n",
       "      <td>-0.393354</td>\n",
       "      <td>-0.205219</td>\n",
       "      <td>1.311616</td>\n",
       "      <td>-0.842607</td>\n",
       "      <td>-0.391001</td>\n",
       "      <td>-0.025599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193652</td>\n",
       "      <td>-0.643314</td>\n",
       "      <td>0.837564</td>\n",
       "      <td>-0.091607</td>\n",
       "      <td>0.155483</td>\n",
       "      <td>0.963728</td>\n",
       "      <td>-1.199049</td>\n",
       "      <td>0.510395</td>\n",
       "      <td>-1.265656</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>0.496230</td>\n",
       "      <td>-1.107668</td>\n",
       "      <td>-0.455296</td>\n",
       "      <td>-0.146612</td>\n",
       "      <td>-0.206907</td>\n",
       "      <td>-1.174915</td>\n",
       "      <td>-0.599754</td>\n",
       "      <td>-0.824691</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120218</td>\n",
       "      <td>-0.494083</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.971604</td>\n",
       "      <td>0.457054</td>\n",
       "      <td>-0.065253</td>\n",
       "      <td>-0.563883</td>\n",
       "      <td>-1.607563</td>\n",
       "      <td>-0.215123</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.173552</td>\n",
       "      <td>-0.020094</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.162922</td>\n",
       "      <td>3.804055</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.768704</td>\n",
       "      <td>0.870800</td>\n",
       "      <td>0.147295</td>\n",
       "      <td>-0.076548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106562</td>\n",
       "      <td>0.575183</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>1.233198</td>\n",
       "      <td>-0.164429</td>\n",
       "      <td>-0.671395</td>\n",
       "      <td>0.321927</td>\n",
       "      <td>-0.724049</td>\n",
       "      <td>0.524060</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.795997</td>\n",
       "      <td>2.202587</td>\n",
       "      <td>1.694647</td>\n",
       "      <td>0.041105</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-1.142155</td>\n",
       "      <td>1.409811</td>\n",
       "      <td>-0.430477</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.344932</td>\n",
       "      <td>-0.482499</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>-0.619764</td>\n",
       "      <td>-0.135552</td>\n",
       "      <td>-0.195766</td>\n",
       "      <td>0.024216</td>\n",
       "      <td>0.465384</td>\n",
       "      <td>0.641519</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>0.976821</td>\n",
       "      <td>1.338091</td>\n",
       "      <td>0.949433</td>\n",
       "      <td>-0.217431</td>\n",
       "      <td>-0.206852</td>\n",
       "      <td>-0.069341</td>\n",
       "      <td>-1.158711</td>\n",
       "      <td>-0.755040</td>\n",
       "      <td>-0.103430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.380703</td>\n",
       "      <td>-0.316064</td>\n",
       "      <td>7.756109</td>\n",
       "      <td>-0.119752</td>\n",
       "      <td>2.456532</td>\n",
       "      <td>-0.567333</td>\n",
       "      <td>-1.697979</td>\n",
       "      <td>-0.543908</td>\n",
       "      <td>1.637743</td>\n",
       "      <td>1.102993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.983460</td>\n",
       "      <td>0.250664</td>\n",
       "      <td>1.218734</td>\n",
       "      <td>2.288974</td>\n",
       "      <td>-1.074715</td>\n",
       "      <td>-0.147400</td>\n",
       "      <td>0.224861</td>\n",
       "      <td>0.578803</td>\n",
       "      <td>20.998139</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167261</td>\n",
       "      <td>-0.512065</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>0.655672</td>\n",
       "      <td>2.194522</td>\n",
       "      <td>-0.456388</td>\n",
       "      <td>-0.625525</td>\n",
       "      <td>-0.513327</td>\n",
       "      <td>-0.409438</td>\n",
       "      <td>1.069436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.084488</td>\n",
       "      <td>0.145485</td>\n",
       "      <td>-0.438194</td>\n",
       "      <td>-0.272311</td>\n",
       "      <td>1.340338</td>\n",
       "      <td>-0.153611</td>\n",
       "      <td>0.283480</td>\n",
       "      <td>0.278199</td>\n",
       "      <td>-0.099728</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>1.762809</td>\n",
       "      <td>1.667054</td>\n",
       "      <td>1.567662</td>\n",
       "      <td>-1.144534</td>\n",
       "      <td>0.344911</td>\n",
       "      <td>-0.420528</td>\n",
       "      <td>1.279246</td>\n",
       "      <td>-0.101866</td>\n",
       "      <td>0.248606</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.505376</td>\n",
       "      <td>1.012517</td>\n",
       "      <td>-0.630327</td>\n",
       "      <td>-0.625191</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.459419</td>\n",
       "      <td>2.028983</td>\n",
       "      <td>-0.488341</td>\n",
       "      <td>-0.101073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295595</td>\n",
       "      <td>-0.178186</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.922397</td>\n",
       "      <td>-0.041703</td>\n",
       "      <td>0.021516</td>\n",
       "      <td>-0.339692</td>\n",
       "      <td>-0.955212</td>\n",
       "      <td>-0.758213</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.881937</td>\n",
       "      <td>0.693712</td>\n",
       "      <td>0.087255</td>\n",
       "      <td>0.599576</td>\n",
       "      <td>0.868512</td>\n",
       "      <td>-0.206792</td>\n",
       "      <td>1.583634</td>\n",
       "      <td>-0.212387</td>\n",
       "      <td>2.125924</td>\n",
       "      <td>0.131963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037097</td>\n",
       "      <td>-0.381783</td>\n",
       "      <td>-0.058532</td>\n",
       "      <td>-0.426677</td>\n",
       "      <td>-0.884686</td>\n",
       "      <td>0.668263</td>\n",
       "      <td>-0.930075</td>\n",
       "      <td>-0.619453</td>\n",
       "      <td>-1.061010</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.158590</td>\n",
       "      <td>-0.746593</td>\n",
       "      <td>2.186332</td>\n",
       "      <td>-0.528871</td>\n",
       "      <td>-1.069380</td>\n",
       "      <td>-0.206884</td>\n",
       "      <td>0.107497</td>\n",
       "      <td>-0.720051</td>\n",
       "      <td>0.363644</td>\n",
       "      <td>0.392779</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096069</td>\n",
       "      <td>-0.643412</td>\n",
       "      <td>-0.139507</td>\n",
       "      <td>2.890818</td>\n",
       "      <td>0.841416</td>\n",
       "      <td>0.493817</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.298212</td>\n",
       "      <td>-0.415633</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.189267</td>\n",
       "      <td>-0.654177</td>\n",
       "      <td>1.258646</td>\n",
       "      <td>2.262840</td>\n",
       "      <td>-0.400264</td>\n",
       "      <td>-0.202146</td>\n",
       "      <td>-0.717895</td>\n",
       "      <td>2.189632</td>\n",
       "      <td>-0.702902</td>\n",
       "      <td>-0.103606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277408</td>\n",
       "      <td>0.359068</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.686799</td>\n",
       "      <td>-0.162618</td>\n",
       "      <td>-0.422645</td>\n",
       "      <td>0.085176</td>\n",
       "      <td>0.755240</td>\n",
       "      <td>-0.346502</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>-0.716995</td>\n",
       "      <td>-0.544833</td>\n",
       "      <td>10.553639</td>\n",
       "      <td>-1.094428</td>\n",
       "      <td>-0.206940</td>\n",
       "      <td>-0.174157</td>\n",
       "      <td>-0.207511</td>\n",
       "      <td>-0.313233</td>\n",
       "      <td>0.315537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.306414</td>\n",
       "      <td>4.746917</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.166875</td>\n",
       "      <td>1.582580</td>\n",
       "      <td>-0.301782</td>\n",
       "      <td>0.341621</td>\n",
       "      <td>-0.411145</td>\n",
       "      <td>0.796459</td>\n",
       "      <td>0.556382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-0.188570</td>\n",
       "      <td>-0.989077</td>\n",
       "      <td>-1.124749</td>\n",
       "      <td>0.207526</td>\n",
       "      <td>-0.678180</td>\n",
       "      <td>-0.206877</td>\n",
       "      <td>1.055166</td>\n",
       "      <td>0.696177</td>\n",
       "      <td>-0.146921</td>\n",
       "      <td>0.090720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056981</td>\n",
       "      <td>-0.268341</td>\n",
       "      <td>1.601446</td>\n",
       "      <td>0.401244</td>\n",
       "      <td>-0.400199</td>\n",
       "      <td>-0.013266</td>\n",
       "      <td>0.091543</td>\n",
       "      <td>-0.049830</td>\n",
       "      <td>-0.615700</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.197406</td>\n",
       "      <td>8.311973</td>\n",
       "      <td>-0.082851</td>\n",
       "      <td>-0.211648</td>\n",
       "      <td>1.687136</td>\n",
       "      <td>0.290910</td>\n",
       "      <td>-0.625617</td>\n",
       "      <td>-0.188346</td>\n",
       "      <td>-0.807891</td>\n",
       "      <td>-0.161744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.415859</td>\n",
       "      <td>-0.480439</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.367771</td>\n",
       "      <td>-0.244583</td>\n",
       "      <td>0.184139</td>\n",
       "      <td>-0.378812</td>\n",
       "      <td>-0.148234</td>\n",
       "      <td>-0.690042</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.149311</td>\n",
       "      <td>-0.863073</td>\n",
       "      <td>-1.037828</td>\n",
       "      <td>0.462384</td>\n",
       "      <td>0.179025</td>\n",
       "      <td>-0.183043</td>\n",
       "      <td>-1.165959</td>\n",
       "      <td>1.189010</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198550</td>\n",
       "      <td>-0.522277</td>\n",
       "      <td>-0.389400</td>\n",
       "      <td>-0.305850</td>\n",
       "      <td>-0.813659</td>\n",
       "      <td>-0.373023</td>\n",
       "      <td>-1.075103</td>\n",
       "      <td>0.434718</td>\n",
       "      <td>0.858534</td>\n",
       "      <td>-0.373156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2          3         4         5         6   \\\n",
       "0  -0.197406 -1.152949 -0.892383   0.407789 -1.112493 -0.183772 -0.981380   \n",
       "1   1.525053 -0.289118 -0.136211  -0.708274  0.421234 -0.206912  1.169015   \n",
       "2  -0.197406 -0.571145 -0.777656  -0.736148 -1.065346 -0.206695  0.102180   \n",
       "3  -0.071813 -0.468509  0.349780  -0.012869 -1.248619 -0.169377 -1.230521   \n",
       "4  -0.197406 -0.554682 -1.301376  -0.485831  5.283663 -0.206940 -0.484873   \n",
       "5  -0.155388  1.227182 -1.263649   3.807565  1.874043 -0.206940  0.115816   \n",
       "6  -0.197406 -0.542280 -0.426669  -0.043602  0.312341 -0.206674 -0.688003   \n",
       "7  -0.188927 -0.455219 -0.514563   0.214680  0.109264 -0.204704  0.031033   \n",
       "8  -0.188381 -0.493381  1.279063  -0.687950 -0.528460 -0.206875  0.096217   \n",
       "9  -0.197406 -0.056241 -0.309892   0.003913  4.685989 -0.206920 -0.543887   \n",
       "10 -0.197406 -0.082919 -0.487022  -0.243317  3.713932 -0.206940 -0.375906   \n",
       "11 -0.197406 -0.775363 -0.957330   0.664804 -0.358645 -0.202307  0.309196   \n",
       "12 -0.197406 -0.788077 -0.108285  -0.683043  1.326500 -0.206940  1.366383   \n",
       "13 -0.057665  1.636301 -0.223654  -0.223119  0.293026  0.206548 -0.962624   \n",
       "14  6.892504  5.093768  0.121310  -0.230621 -0.028129 -0.206207 -0.101754   \n",
       "15 -0.197406  1.026031  0.655874   0.699575  4.219049 -0.129809 -0.544149   \n",
       "16 -0.197406 -0.972207 -1.484722   1.891841  0.579962 -0.196931 -0.455378   \n",
       "17 -0.197406  0.378201  0.947177  -0.436224  0.390505 -0.206922 -0.589436   \n",
       "18 -0.090229 -0.025331 -0.694131   0.090559 -0.776531 -0.206940 -0.684280   \n",
       "19 -0.191717  0.696165 -0.566189  -0.098065  2.912579 -0.206940 -0.314335   \n",
       "20 -0.185949  0.272660  2.126326  -0.674972 -0.311515 -0.206195  0.397774   \n",
       "21 -0.181539 -0.776908  0.054722   0.619635 -0.085953  1.221667 -1.100209   \n",
       "22 -0.180384 -0.112076 -0.959738   0.445562 -0.966646 -0.191316 -0.563976   \n",
       "23 -0.189507 -0.630834  0.107317   0.684236  2.228339 -0.206940  0.565500   \n",
       "24 -0.174668  1.398851  1.576386  -0.624840 -0.909349 -0.189027  0.038566   \n",
       "25 -0.197406  0.378201  0.947177  -0.436224  0.390505 -0.206922 -0.589436   \n",
       "26 -0.197406 -0.423606  0.754155   0.163767 -1.381171 -0.186300 -0.261924   \n",
       "27 -0.197406 -0.533572  0.636675  -0.628389 -1.081280 -0.206940  0.403653   \n",
       "28 -0.087447  0.723271  0.278285   0.173416  0.033805 -0.202569 -1.359015   \n",
       "29 -0.163114  1.714387 -1.235911  -0.390258  0.467395 -0.027505 -0.975821   \n",
       "30 -0.179800 -0.675387 -0.161026  -0.250405 -1.159355 -0.192276  0.778843   \n",
       "31 -0.087024 -0.787774  0.952674  -0.097588  2.531243 -0.201281 -0.031597   \n",
       "32 -0.176095 -0.257900 -0.146450  -0.710858 -0.233679 -0.187097  0.506380   \n",
       "33  0.447306 -0.120772 -0.869098  -0.390045 -0.714890 -0.206940 -0.010379   \n",
       "34 -0.182442 -0.906412  2.600997  -0.132377  1.415686 -0.206940 -0.482477   \n",
       "35 -0.151119 -0.269225  0.608706  -0.637279 -1.151401 -0.173922 -0.422851   \n",
       "36 -0.197406 -0.827841 -0.263335   0.654868 -0.393354 -0.205219  1.311616   \n",
       "37 -0.197406  0.496230 -1.107668  -0.455296 -0.146612 -0.206907 -1.174915   \n",
       "38 -0.173552 -0.020094 -0.000512  -0.162922  3.804055 -0.206940 -0.768704   \n",
       "39 -0.197406 -0.795997  2.202587   1.694647  0.041105 -0.206940 -1.142155   \n",
       "40 -0.197406  0.976821  1.338091   0.949433 -0.217431 -0.206852 -0.069341   \n",
       "41  0.983460  0.250664  1.218734   2.288974 -1.074715 -0.147400  0.224861   \n",
       "42 -0.084488  0.145485 -0.438194  -0.272311  1.340338 -0.153611  0.283480   \n",
       "43 -0.197406 -0.505376  1.012517  -0.630327 -0.625191 -0.206940 -0.459419   \n",
       "44  0.881937  0.693712  0.087255   0.599576  0.868512 -0.206792  1.583634   \n",
       "45 -0.158590 -0.746593  2.186332  -0.528871 -1.069380 -0.206884  0.107497   \n",
       "46 -0.189267 -0.654177  1.258646   2.262840 -0.400264 -0.202146 -0.717895   \n",
       "47 -0.197406 -0.716995 -0.544833  10.553639 -1.094428 -0.206940 -0.174157   \n",
       "48 -0.188570 -0.989077 -1.124749   0.207526 -0.678180 -0.206877  1.055166   \n",
       "49 -0.197406  8.311973 -0.082851  -0.211648  1.687136  0.290910 -0.625617   \n",
       "50 -0.149311 -0.863073 -1.037828   0.462384  0.179025 -0.183043 -1.165959   \n",
       "\n",
       "          7          8         9   ...        88        89        90  \\\n",
       "0  -1.468625  -0.345237 -0.161744  ... -0.284202 -1.410780 -0.389400   \n",
       "1  -0.057043  -0.158037 -0.161744  ...  1.101916  0.981233 -0.389400   \n",
       "2  -0.187399   0.100647  0.242685  ...  0.644850 -0.347716 -0.389400   \n",
       "3  -0.884092  15.632001 -0.003431  ... -0.113438 -0.372181  1.750784   \n",
       "4  -1.110872  -0.142478 -0.161744  ... -0.427940 -0.445768 -0.389400   \n",
       "5  -0.954015  -0.176646 -0.161744  ... -0.231007  0.639378  2.991752   \n",
       "6   1.363689   0.897546 -0.161744  ...  0.612690  0.257477  1.337947   \n",
       "7   1.051813  -0.174715 -0.101176  ...  0.666046 -0.714006 -0.389400   \n",
       "8  -1.225756   2.041290  0.031670  ... -0.184560  0.916197 -0.098887   \n",
       "9   0.980489  -0.141224 -0.120501  ... -0.135252 -0.040952 -0.389400   \n",
       "10  1.187749  -0.199322 -0.099939  ...  0.345640  1.023961 -0.389400   \n",
       "11 -1.157995   0.185083 -0.098569  ... -0.396972 -0.126220  0.179878   \n",
       "12  0.648637  -0.543128 -0.033877  ...  0.549263  0.245194 -0.389400   \n",
       "13  0.638227  -0.833195 -0.161744  ... -0.419911  0.265130  0.172842   \n",
       "14  0.269929   0.664296  0.200514  ...  0.504311  0.579815 -0.389400   \n",
       "15 -0.530409  -0.535182 -0.161744  ... -0.358002 -0.910863 -0.389400   \n",
       "16 -0.975824  -0.376939  0.012565  ... -0.169920 -0.869151 -0.389400   \n",
       "17 -0.048283  -0.506207 -0.125273  ...  0.077038  1.089771 -0.389400   \n",
       "18  1.065592   0.385908 -0.161744  ... -0.110133 -0.635497 -0.101940   \n",
       "19  1.007171  -0.158989 -0.080451  ... -0.142830  0.943173  0.343221   \n",
       "20 -0.549987  -0.197009  0.042835  ... -0.076638  0.190350  0.901149   \n",
       "21 -0.529115   0.944206 -0.161744  ... -0.386839 -1.398304  2.675155   \n",
       "22  0.068553   0.097248 -0.161744  ... -0.342878  0.127456 -0.389400   \n",
       "23  1.008931  -0.589119 -0.161744  ...  0.071072 -0.444733  0.882100   \n",
       "24 -0.007329  -0.203308 -0.121134  ... -0.226987  1.862962 -0.389400   \n",
       "25 -0.048283  -0.506207 -0.125273  ...  0.077038  1.089771 -0.389400   \n",
       "26  0.402806  -0.301895 -0.161744  ... -0.028618 -0.751451  1.341730   \n",
       "27 -0.888978  -0.206936 -0.053644  ...  0.884230  0.495166  0.097709   \n",
       "28  1.046378   0.906244 -0.115537  ... -0.244859  0.460015 -0.389400   \n",
       "29 -0.244783  -0.326672 -0.161744  ... -0.374046 -0.930736 -0.389400   \n",
       "30 -0.680546   0.478560 -0.098863  ... -0.298717 -0.041181 -0.389400   \n",
       "31 -0.432273  -0.448440 -0.013903  ... -0.248387 -1.270679 -0.389400   \n",
       "32 -0.116203   0.654617 -0.161744  ...  0.213123  1.421938 -0.160746   \n",
       "33  0.491797  -0.622245 -0.015538  ... -0.278448  0.532293 -0.389400   \n",
       "34 -0.375368   0.067966  0.657763  ...  0.727083 -0.254941  0.092266   \n",
       "35  1.540069  -0.214420 -0.161744  ... -0.243530  0.462879  0.504506   \n",
       "36 -0.842607  -0.391001 -0.025599  ... -0.193652 -0.643314  0.837564   \n",
       "37 -0.599754  -0.824691 -0.161744  ... -0.120218 -0.494083 -0.389400   \n",
       "38  0.870800   0.147295 -0.076548  ... -0.106562  0.575183 -0.389400   \n",
       "39  1.409811  -0.430477 -0.161744  ... -0.344932 -0.482499  0.010163   \n",
       "40 -1.158711  -0.755040 -0.103430  ... -0.380703 -0.316064  7.756109   \n",
       "41  0.578803  20.998139 -0.161744  ... -0.167261 -0.512065 -0.389400   \n",
       "42  0.278199  -0.099728 -0.161744  ...  1.762809  1.667054  1.567662   \n",
       "43  2.028983  -0.488341 -0.101073  ... -0.295595 -0.178186 -0.389400   \n",
       "44 -0.212387   2.125924  0.131963  ... -0.037097 -0.381783 -0.058532   \n",
       "45 -0.720051   0.363644  0.392779  ... -0.096069 -0.643412 -0.139507   \n",
       "46  2.189632  -0.702902 -0.103606  ... -0.277408  0.359068 -0.389400   \n",
       "47 -0.207511  -0.313233  0.315537  ... -0.306414  4.746917 -0.389400   \n",
       "48  0.696177  -0.146921  0.090720  ...  0.056981 -0.268341  1.601446   \n",
       "49 -0.188346  -0.807891 -0.161744  ... -0.415859 -0.480439 -0.389400   \n",
       "50  1.189010   0.076184  0.010032  ... -0.198550 -0.522277 -0.389400   \n",
       "\n",
       "          91        92         93        94        95        96        97  \n",
       "0  -1.135510 -0.303629  10.998169 -0.070555  0.845148 -1.067224 -0.373156  \n",
       "1  -1.064894 -1.242841   0.057434  1.361961  0.319770  2.069493 -0.373156  \n",
       "2  -0.706712 -0.465162   1.953518 -0.228148 -0.674436 -0.973728 -0.373156  \n",
       "3  -0.154840 -0.872758   0.128107  0.643646  0.422515  0.546828 -0.373156  \n",
       "4  -0.773266 -0.019030   0.426392  1.398153 -0.913908  0.004746 -0.373156  \n",
       "5  -0.604531 -0.326557  -0.186227  0.230351 -0.434106 -0.585346 -0.373156  \n",
       "6   0.049874 -0.056159  -0.471635  0.287637 -0.272107  2.736600  2.052665  \n",
       "7   0.310410 -0.260173  -0.426441 -0.318067 -0.463256  0.480000 -0.373156  \n",
       "8   0.515465  0.686147  -0.162070 -1.298626  3.364564 -0.442716 -0.373156  \n",
       "9   0.064767  0.706438  -0.371978  1.750467 -0.585226  0.928558 -0.373156  \n",
       "10 -0.177260  0.108126  -0.467255  1.083701 -0.346616  0.249563 -0.373156  \n",
       "11 -0.901076  0.529862   0.113559 -0.640480 -0.420425  0.370950 -0.373156  \n",
       "12 -0.508508 -0.619410  -0.045688  1.378305 -0.375478 -0.971814 -0.373156  \n",
       "13  4.764838 -0.556687  -0.618751 -0.658737 -0.705549 -1.135233 -0.373156  \n",
       "14 -0.791721 -1.373242  -0.154023  0.308769 -0.754756  0.061991 -0.373156  \n",
       "15  1.947498 -1.083991  -0.339996  0.141742  0.207014 -1.402438 -0.373156  \n",
       "16  0.158307 -0.568464   3.810881 -0.014879  0.861589 -1.825590 -0.373156  \n",
       "17  0.217744  0.752242  -0.196899 -1.577878  0.297272  0.950882 -0.373156  \n",
       "18 -1.033944 -1.245750  -0.242662 -0.881734  0.265528  0.318674  1.241697  \n",
       "19  0.797598 -0.189391  -0.391425  1.063183 -0.115755  1.599577 -0.373156  \n",
       "20  1.652483 -0.579729  -0.271578 -1.108678  0.946713 -1.155294 -0.373156  \n",
       "21  0.397213 -0.456293  -0.461792 -1.215308 -0.090502 -0.521223 -0.373156  \n",
       "22  0.692614  0.709436  -0.255422  0.150369  0.458735  1.149100  1.166006  \n",
       "23 -0.180800 -1.151414  -0.058924 -0.225916 -0.338011 -0.112032 -0.373156  \n",
       "24 -1.135664  0.939571  -0.464304 -0.173033  0.046406 -0.660744  0.654817  \n",
       "25  0.217744  0.752242  -0.196899 -1.577878  0.297272  0.950882 -0.373156  \n",
       "26  1.723305 -0.461954  -0.111834 -1.397333 -0.070824  0.431583 -0.373156  \n",
       "27 -0.217577 -0.899280   1.542499  1.420682 -0.143602  0.528691 -0.373156  \n",
       "28  1.242272 -1.387882  -0.565250  0.179404 -0.364372 -0.828205 -0.373156  \n",
       "29 -0.973690 -0.293373   0.365655  0.019339  1.019428 -1.829456 -0.373156  \n",
       "30  1.425854  0.557112  -0.330954 -0.471067 -0.211074 -0.145525 -0.373156  \n",
       "31  2.099330 -0.346175  -0.034327  1.051292 -0.650822 -1.879435 -0.373156  \n",
       "32  0.714260 -0.286305  -0.345904 -0.701443  2.567135  0.441304  0.911344  \n",
       "33 -1.583679 -0.091866  -0.275838  2.799386 -0.333413  0.119760 -0.373156  \n",
       "34 -0.371777  0.168890  -0.248581  0.835665  0.902398  0.398696 -0.373156  \n",
       "35  0.225061 -0.563461  -0.602541 -1.970501 -0.202102 -0.687050 -0.373156  \n",
       "36 -0.091607  0.155483   0.963728 -1.199049  0.510395 -1.265656 -0.373156  \n",
       "37  0.971604  0.457054  -0.065253 -0.563883 -1.607563 -0.215123 -0.373156  \n",
       "38  1.233198 -0.164429  -0.671395  0.321927 -0.724049  0.524060 -0.373156  \n",
       "39 -0.619764 -0.135552  -0.195766  0.024216  0.465384  0.641519 -0.373156  \n",
       "40 -0.119752  2.456532  -0.567333 -1.697979 -0.543908  1.637743  1.102993  \n",
       "41  0.655672  2.194522  -0.456388 -0.625525 -0.513327 -0.409438  1.069436  \n",
       "42 -1.144534  0.344911  -0.420528  1.279246 -0.101866  0.248606 -0.373156  \n",
       "43 -0.922397 -0.041703   0.021516 -0.339692 -0.955212 -0.758213 -0.373156  \n",
       "44 -0.426677 -0.884686   0.668263 -0.930075 -0.619453 -1.061010 -0.373156  \n",
       "45  2.890818  0.841416   0.493817  0.026647  0.298212 -0.415633 -0.373156  \n",
       "46 -0.686799 -0.162618  -0.422645  0.085176  0.755240 -0.346502 -0.373156  \n",
       "47 -0.166875  1.582580  -0.301782  0.341621 -0.411145  0.796459  0.556382  \n",
       "48  0.401244 -0.400199  -0.013266  0.091543 -0.049830 -0.615700 -0.373156  \n",
       "49 -0.367771 -0.244583   0.184139 -0.378812 -0.148234 -0.690042 -0.373156  \n",
       "50 -0.305850 -0.813659  -0.373023 -1.075103  0.434718  0.858534 -0.373156  \n",
       "\n",
       "[51 rows x 98 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c7b27529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.621164</td>\n",
       "      <td>0.616829</td>\n",
       "      <td>0.235922</td>\n",
       "      <td>0.608220</td>\n",
       "      <td>0.598571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.085804</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.534161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.534286</td>\n",
       "      <td>0.540447</td>\n",
       "      <td>0.547073</td>\n",
       "      <td>0.094487</td>\n",
       "      <td>0.549379</td>\n",
       "      <td>0.567429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.085804</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.526398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TP    FP    FN    TN      SENS      SPEC      PREC       ACC       MCC  \\\n",
       "0  12.0   7.4   8.0  12.8  0.600000  0.634286  0.621164  0.616829  0.235922   \n",
       "1  17.0  12.0  11.0  11.0  0.607143  0.478261  0.586207  0.549020  0.085804   \n",
       "2  11.2   9.4   8.8  10.8  0.560000  0.534286  0.540447  0.547073  0.094487   \n",
       "3  17.0  12.0  11.0  11.0  0.607143  0.478261  0.586207  0.549020  0.085804   \n",
       "\n",
       "         F1       AUC  \n",
       "0  0.608220  0.598571  \n",
       "1  0.596491  0.534161  \n",
       "2  0.549379  0.567429  \n",
       "3  0.596491  0.526398  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    cv = LeaveOneOut()\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x2, y_train):\n",
    "        train_x = x2.iloc[train,:]\n",
    "        test_x = x2.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_val)[:,1]\n",
    "    predict_label_y = clf.predict(x_val)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bcc9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from numpy import reshape\n",
    "import seaborn as sns\n",
    "import pandas as pd  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3a9119d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(201, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "x = x_train\n",
    "y= x_valid\n",
    "x_train_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(x)\n",
    "x_train_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c76241a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_valid_embedded = TSNE(n_components=3,).fit_transform(y) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "06d691b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_tsne' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x_valid_embedded\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(x_valid_embedded)\n\u001b[1;32m      2\u001b[0m x_train_embedded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(x_train_embedded)\n\u001b[0;32m----> 3\u001b[0m test_tsne\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtest_tsne\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_tsne' is not defined"
     ]
    }
   ],
   "source": [
    "x_valid_embedded=pd.DataFrame(x_valid_embedded)\n",
    "x_train_embedded = pd.DataFrame(x_train_embedded)\n",
    "test_tsne=pd.DataFrame(test_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0ba673e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(random_state=1)\n",
      "GradientBoostingClassifier(random_state=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>SENS</th>\n",
       "      <th>SPEC</th>\n",
       "      <th>PREC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.504286</td>\n",
       "      <td>0.488722</td>\n",
       "      <td>0.492317</td>\n",
       "      <td>-0.015945</td>\n",
       "      <td>0.483921</td>\n",
       "      <td>0.513024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>-0.012411</td>\n",
       "      <td>0.341463</td>\n",
       "      <td>0.579193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.559418</td>\n",
       "      <td>0.561707</td>\n",
       "      <td>0.123790</td>\n",
       "      <td>0.553494</td>\n",
       "      <td>0.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.204303</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.559783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TP    FP    FN    TN      SENS      SPEC      PREC       ACC       MCC  \\\n",
       "0   9.6  10.0  10.4  10.2  0.480000  0.504286  0.488722  0.492317 -0.015945   \n",
       "1   7.0   6.0  21.0  17.0  0.250000  0.739130  0.538462  0.470588 -0.012411   \n",
       "2  11.0   8.6   9.0  11.6  0.550000  0.573333  0.559418  0.561707  0.123790   \n",
       "3  10.0   4.0  18.0  19.0  0.357143  0.826087  0.714286  0.568627  0.204303   \n",
       "\n",
       "         F1       AUC  \n",
       "0  0.483921  0.513024  \n",
       "1  0.341463  0.579193  \n",
       "2  0.553494  0.573000  \n",
       "3  0.476190  0.559783  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics = []\n",
    "for i in classifier_list:\n",
    "#data_rand\n",
    "    print(i)\n",
    "    from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "    import numpy as np\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    #kf.get_n_splits(X)\n",
    "    #kf.get_n_splits(X)\n",
    "    cc = []\n",
    "    dd = []\n",
    "    ee = []\n",
    "    clf = i\n",
    "    auc_scores=[]\n",
    "    for train, test in skf.split(x_train_embedded, y_train):\n",
    "        train_x = x_train_embedded.iloc[train,:]\n",
    "        test_x = x_train_embedded.iloc[test]\n",
    "        train_y = y_train[train]\n",
    "        test_y = y_train[test]\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        predict_y = clf.predict_proba(test_x)[:,1]\n",
    "        cc.append(clf.predict(test_x))\n",
    "        ee.append(clf.predict_proba(test_x)[:,1])\n",
    "        dd.append(test_y)\n",
    "        auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "    np.array(auc_scores).mean()\n",
    "    #Training_matrics\n",
    "    metrics = []\n",
    "    for i in range(5):\n",
    "        metrics.append(calc_metrics(confusion_matrix(dd[i], cc[i]).ravel()))\n",
    "    train_matrics=pd.DataFrame(metrics, columns=['tp','fp','fn','tn','sens','spec','prec','acc','mcc','f1'])\n",
    "    asdf = list(train_matrics.mean()) \n",
    "    asdf.append(np.array(auc_scores).mean())\n",
    "    final_metrics.append(asdf)\n",
    "    \n",
    "    #testing metrics\n",
    "    predict_y = clf.predict_proba(x_valid_embedded)[:,1]\n",
    "    predict_label_y = clf.predict(x_valid_embedded)\n",
    "    test_auc = roc_auc_score(y_valid, predict_y)\n",
    "    conf_mat_test = confusion_matrix(y_valid,predict_label_y).ravel()\n",
    "    \n",
    "    test_metrics = list(calc_metrics(conf_mat_test))\n",
    "    test_metrics.append(test_auc)\n",
    "    final_metrics.append(test_metrics)\n",
    "\n",
    "    \n",
    "pd.DataFrame(final_metrics, columns=['TP','FP','FN','TN','SENS','SPEC','PREC','ACC','MCC','F1','AUC']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "435f4d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "\n",
    "# Load your gene expression data\n",
    "\n",
    "\n",
    "# Create a Lasso object with the desired alpha value\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the Lasso model to your data\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# Get the coefficients of the fitted model\n",
    "coefficients = lasso.coef_\n",
    "\n",
    "# Get the indices of the nonzero coefficients\n",
    "selected_indices = np.where(coefficients != 0)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "721ef60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "        15,  16,  17,  18,  19,  20,  21,  24,  25,  26,  28,  29,  30,\n",
       "        31,  32,  33,  34,  35,  36,  38,  40,  41,  42,  43,  44,  47,\n",
       "        48,  49,  50,  51,  53,  55,  56,  57,  58,  60,  61,  62,  63,\n",
       "        65,  67,  69,  70,  72,  73,  75,  76,  77,  78,  79,  80,  81,\n",
       "        82,  83,  84,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
       "        99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113,\n",
       "       114, 115, 116, 117, 118, 119, 121, 122, 124, 125, 126, 127, 128,\n",
       "       129, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 151, 152, 153, 154, 155, 156, 157, 159,\n",
       "       161, 162, 163, 164, 165, 167, 168, 169, 171, 172, 173, 174, 175,\n",
       "       176, 177, 178, 179, 180, 181, 184, 185, 186, 187, 190, 191, 192,\n",
       "       194, 195, 196, 197, 199])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bad997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd462155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "25e84c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4a77186",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "continuous-multioutput format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m cv \u001b[38;5;241m=\u001b[39m LeaveOneOut()\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m cross_val_predict(model, x_train, y_train, cv\u001b[38;5;241m=\u001b[39mcv, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m auroc_score \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauroc_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:580\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    574\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/metrics/_base.py:72\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     70\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m binary_metric(y_true, y_score, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "\u001b[0;31mValueError\u001b[0m: continuous-multioutput format is not supported"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "y_pred = cross_val_predict(model, x_train, y_train, cv=cv, method='predict_proba')\n",
    "\n",
    "auroc_score = roc_auc_score(y, y_pred[:, 1])\n",
    "\n",
    "print(f\"AUROC score: {auroc_score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2a1a480d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [52], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m train_y \u001b[38;5;241m=\u001b[39m y_train[train]\n\u001b[1;32m     11\u001b[0m test_y \u001b[38;5;241m=\u001b[39m y_train[test]\n\u001b[0;32m---> 12\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(train_X, train_y)\n\u001b[1;32m     13\u001b[0m predict_y \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(test_X)[:,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m auc_scores\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(test_y, predict_y))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import StratifiedKFold, KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "cv = LeaveOneOut()\n",
    "clf = i\n",
    "auc_scores=[]\n",
    "for train, test in skf.split(x_train, y_train):\n",
    "    train_X = x_train.iloc[train,:]\n",
    "    test_X = x_train.iloc[test]\n",
    "    train_y = y_train[train]\n",
    "    test_y = y_train[test]\n",
    "    clf.fit(train_X, train_y)\n",
    "    predict_y = clf.predict_proba(test_X)[:,1]\n",
    "    auc_scores.append(roc_auc_score(test_y, predict_y))\n",
    "np.array(auc_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d5cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
