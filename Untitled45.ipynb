{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbA740Dfx_aV"
   },
   "source": [
    "## FLAML: A Fast and Lightweight AutoML Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhC_ulqGvYSq",
    "outputId": "7b48070b-31ec-4e52-e3f3-3441caf1c236",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flaml\n",
      "  Downloading FLAML-1.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m307.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flaml) (1.10.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flaml) (1.5.3)\n",
      "Requirement already satisfied: NumPy>=1.17.0rc1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flaml) (1.23.5)\n",
      "Collecting lightgbm>=2.3.1\n",
      "  Using cached lightgbm-3.3.5.tar.gz (1.5 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flaml) (1.2.2)\n",
      "Requirement already satisfied: xgboost>=0.90 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from flaml) (1.7.4)\n",
      "Requirement already satisfied: wheel in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from lightgbm>=2.3.1->flaml) (0.40.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.4->flaml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.4->flaml) (2022.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=0.24->flaml) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas>=1.1.4->flaml) (1.16.0)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[86 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib\n",
      "  \u001b[31m   \u001b[0m creating build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/callback.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/compat.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/plotting.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/__init__.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/engine.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/dask.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/basic.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/libpath.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing lightgbm.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to lightgbm.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to lightgbm.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching 'build'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.so' under directory 'lightgbm'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.so' under directory 'compile'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.dll' under directory 'compile/Release'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
      "  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
      "  \u001b[31m   \u001b[0m INFO:wheel:installing to build/bdist.macosx-10.9-universal2/wheel\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile the library.\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile with CMake.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 95, in silent_call\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd, stderr=log, stdout=log)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 364, in check_call\n",
      "  \u001b[31m   \u001b[0m     retcode = call(*popenargs, **kwargs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 345, in call\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as p:\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 969, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 1845, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 334, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='lightgbm',\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 177, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 193, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/wheel/bdist_wheel.py\", line 378, in run\n",
      "  \u001b[31m   \u001b[0m     self.run_command(\"install\")\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/cmd.py\", line 317, in run_command\n",
      "  \u001b[31m   \u001b[0m     self.distribution.run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 248, in run\n",
      "  \u001b[31m   \u001b[0m     compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu, use_cuda=self.cuda, use_mpi=self.mpi,\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 198, in compile_cpp\n",
      "  \u001b[31m   \u001b[0m     silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake and all required dependencies first')\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 99, in silent_call\n",
      "  \u001b[31m   \u001b[0m     raise Exception(\"\\n\".join((error_msg, LOG_NOTICE)))\n",
      "  \u001b[31m   \u001b[0m Exception: Please install CMake and all required dependencies first\n",
      "  \u001b[31m   \u001b[0m The full version of error log was saved into /Users/anandr/LightGBM_compilation.log\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for lightgbm\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for lightgbm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build lightgbm\n",
      "Installing collected packages: lightgbm, flaml\n",
      "  Running setup.py install for lightgbm ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for lightgbm\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running install\n",
      "  \u001b[31m   \u001b[0m /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile the library.\n",
      "  \u001b[31m   \u001b[0m INFO:LightGBM:Starting to compile with CMake.\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 95, in silent_call\n",
      "  \u001b[31m   \u001b[0m     subprocess.check_call(cmd, stderr=log, stdout=log)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 364, in check_call\n",
      "  \u001b[31m   \u001b[0m     retcode = call(*popenargs, **kwargs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 345, in call\n",
      "  \u001b[31m   \u001b[0m     with Popen(*popenargs, **kwargs) as p:\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 969, in __init__\n",
      "  \u001b[31m   \u001b[0m     self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py\", line 1845, in _execute_child\n",
      "  \u001b[31m   \u001b[0m     raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  \u001b[31m   \u001b[0m FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m During handling of the above exception, another exception occurred:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 334, in <module>\n",
      "  \u001b[31m   \u001b[0m     setup(name='lightgbm',\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 177, in setup\n",
      "  \u001b[31m   \u001b[0m     return run_commands(dist)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/core.py\", line 193, in run_commands\n",
      "  \u001b[31m   \u001b[0m     dist.run_commands()\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 968, in run_commands\n",
      "  \u001b[31m   \u001b[0m     self.run_command(cmd)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/dist.py\", line 1217, in run_command\n",
      "  \u001b[31m   \u001b[0m     super().run_command(command)\n",
      "  \u001b[31m   \u001b[0m   File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/_distutils/dist.py\", line 987, in run_command\n",
      "  \u001b[31m   \u001b[0m     cmd_obj.run()\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 248, in run\n",
      "  \u001b[31m   \u001b[0m     compile_cpp(use_mingw=self.mingw, use_gpu=self.gpu, use_cuda=self.cuda, use_mpi=self.mpi,\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 198, in compile_cpp\n",
      "  \u001b[31m   \u001b[0m     silent_call(cmake_cmd, raise_error=True, error_msg='Please install CMake and all required dependencies first')\n",
      "  \u001b[31m   \u001b[0m   File \"/private/var/folders/px/t3y_9w795y96ggv476lfg7dh0000gn/T/pip-install-69q_o71r/lightgbm_14d3f0919ae645ae8b5063b4f49467d0/setup.py\", line 99, in silent_call\n",
      "  \u001b[31m   \u001b[0m     raise Exception(\"\\n\".join((error_msg, LOG_NOTICE)))\n",
      "  \u001b[31m   \u001b[0m Exception: Please install CMake and all required dependencies first\n",
      "  \u001b[31m   \u001b[0m The full version of error log was saved into /Users/anandr/LightGBM_compilation.log\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
      "\u001b[31m╰─>\u001b[0m lightgbm\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install flaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00xUXNvfwyXV"
   },
   "source": [
    "# Classification Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jDEkaxcDvJuB",
    "outputId": "a92f1e8e-7f19-4389-bc99-f44c3d81ce82"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[flaml.automl: 10-01 12:29:07] {1432} INFO - Evaluation method: cv\n",
      "[flaml.automl: 10-01 12:29:07] {1478} INFO - Minimizing error metric: 1-accuracy\n",
      "[flaml.automl: 10-01 12:29:07] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree', 'lrl1']\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1866} INFO - Estimated sufficient time budget=249s. Estimated necessary time budget=5s.\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.0s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.0733,\tbest estimator lgbm's best error=0.0733\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.1s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0533,\tbest estimator lgbm's best error=0.0533\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0467,\tbest estimator lgbm's best error=0.0467\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:07] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:07] {1748} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:08] {1944} INFO -  at 0.4s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:08] {1748} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:08] {1944} INFO -  at 0.4s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:08] {1748} INFO - iteration 12, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:29:09] {1944} INFO -  at 1.6s,\testimator extra_tree's best error=0.0667,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:09] {1748} INFO - iteration 13, current learner rf\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.7s,\testimator rf's best error=0.0733,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 14, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.7s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 2.9s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 21, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.0s,\testimator xgboost's best error=0.0600,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.0400,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:10] {1944} INFO -  at 3.1s,\testimator xgboost's best error=0.0467,\tbest estimator lgbm's best error=0.0400\n",
      "[flaml.automl: 10-01 12:29:10] {1748} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:29:11] {1944} INFO -  at 4.2s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:11] {1748} INFO - iteration 26, current learner catboost\n",
      "[flaml.automl: 10-01 12:29:12] {1944} INFO -  at 4.8s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:12] {1748} INFO - iteration 27, current learner rf\n",
      "[flaml.automl: 10-01 12:29:13] {1944} INFO -  at 6.0s,\testimator rf's best error=0.0600,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:13] {1748} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:13] {1944} INFO -  at 6.0s,\testimator xgboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:13] {1748} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:29:14] {1944} INFO -  at 7.1s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:14] {1748} INFO - iteration 30, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.4s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.4s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator xgboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.5s,\testimator lgbm's best error=0.0400,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 36, current learner catboost\n",
      "[flaml.automl: 10-01 12:29:16] {1944} INFO -  at 8.9s,\testimator catboost's best error=0.0467,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:16] {1748} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:29:17] {1944} INFO -  at 10.0s,\testimator extra_tree's best error=0.0333,\tbest estimator extra_tree's best error=0.0333\n",
      "[flaml.automl: 10-01 12:29:17] {2043} INFO - selected model: ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=6,\n",
      "                     n_estimators=4, n_jobs=-1)\n",
      "[flaml.automl: 10-01 12:29:17] {2106} INFO - retrain extra_tree for 0.2s\n",
      "[flaml.automl: 10-01 12:29:17] {2110} INFO - retrained model: ExtraTreesClassifier(max_features=0.9692029582222275, max_leaf_nodes=6,\n",
      "                     n_estimators=4, n_jobs=-1)\n",
      "[flaml.automl: 10-01 12:29:17] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-01 12:29:17] {1541} INFO - Time taken to find the best model: 4.214092969894409\n"
     ]
    }
   ],
   "source": [
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_iris\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,  # in seconds\n",
    "    \"metric\": 'accuracy',\n",
    "    \"task\": 'classification',\n",
    "    \"log_file_name\": \"iris.log\",\n",
    "}\n",
    "X_train, y_train = load_iris(return_X_y=True)\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-3p9iLJvWwz",
    "outputId": "db2106b2-0404-4ab2-d9fa-e68e72f29922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [1.         0.         0.        ]\n",
      " [0.         0.87678571 0.12321429]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.46869756 0.53130244]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.94345238 0.05654762]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.87678571 0.12321429]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.87678571 0.12321429]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.46869756 0.53130244]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.87678571 0.12321429]\n",
      " [0.         0.87678571 0.12321429]\n",
      " [0.         0.36014493 0.63985507]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.30359731 0.69640269]\n",
      " [0.         0.83950501 0.16049499]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.95416667 0.04583333]\n",
      " [0.         0.87678571 0.12321429]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.9125     0.0875    ]\n",
      " [0.         0.97916667 0.02083333]\n",
      " [0.         0.9375     0.0625    ]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.30359731 0.69640269]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.83950501 0.16049499]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.30359731 0.69640269]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.36014493 0.63985507]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.36014493 0.63985507]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.46869756 0.53130244]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.46869756 0.53130244]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.46869756 0.53130244]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.30359731 0.69640269]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.79783835 0.20216165]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.30359731 0.69640269]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.36014493 0.63985507]\n",
      " [0.         0.04943064 0.95056936]\n",
      " [0.         0.00595238 0.99404762]\n",
      " [0.         0.30359731 0.69640269]]\n",
      "<flaml.model.ExtraTreeEstimator object at 0x7f0a9ea30550>\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "print(automl.predict_proba(X_train))\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXE4twtlwk1x"
   },
   "source": [
    "# Regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENQ6nHCMwEFi",
    "outputId": "b4c4bdff-34d7-4e5d-ac9e-82ddbeae3f04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this case special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows:\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and:\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "[flaml.automl: 10-01 12:31:13] {1432} INFO - Evaluation method: cv\n",
      "[flaml.automl: 10-01 12:31:13] {1478} INFO - Minimizing error metric: 1-r2\n",
      "[flaml.automl: 10-01 12:31:14] {1515} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'catboost', 'xgboost', 'extra_tree']\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1866} INFO - Estimated sufficient time budget=269s. Estimated necessary time budget=1s.\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.0s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.6257,\tbest estimator lgbm's best error=0.6257\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 2, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.1s,\testimator lgbm's best error=0.3498,\tbest estimator lgbm's best error=0.3498\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 3, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.1s,\testimator xgboost's best error=3.1963,\tbest estimator lgbm's best error=0.3498\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 4, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 5, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2466,\tbest estimator lgbm's best error=0.2466\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.2s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 7, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 8, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.3s,\testimator lgbm's best error=0.2087,\tbest estimator lgbm's best error=0.2087\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 9, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.4s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 10, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:14] {1944} INFO -  at 0.4s,\testimator xgboost's best error=3.1963,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:14] {1748} INFO - iteration 11, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:31:15] {1944} INFO -  at 1.5s,\testimator extra_tree's best error=0.3471,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:15] {1748} INFO - iteration 12, current learner rf\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.7s,\testimator rf's best error=0.2872,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.7s,\testimator xgboost's best error=0.8624,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.3204,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 15, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.8s,\testimator xgboost's best error=0.3204,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 16, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.8s,\testimator lgbm's best error=0.1682,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 17, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 2.9s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1682\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 3.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 19, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:16] {1944} INFO -  at 3.0s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:16] {1748} INFO - iteration 20, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 21, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.2s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 23, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.3s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 24, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:17] {1944} INFO -  at 3.3s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:17] {1748} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.5s,\testimator extra_tree's best error=0.2252,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 26, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 28, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:18] {1944} INFO -  at 4.6s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:18] {1748} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:31:19] {1944} INFO -  at 5.8s,\testimator extra_tree's best error=0.2252,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:19] {1748} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:19] {1944} INFO -  at 5.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:19] {1748} INFO - iteration 31, current learner catboost\n",
      "[flaml.automl: 10-01 12:31:20] {1944} INFO -  at 6.8s,\testimator catboost's best error=0.1523,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:20] {1748} INFO - iteration 32, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:20] {1944} INFO -  at 6.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:20] {1748} INFO - iteration 33, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:20] {1944} INFO -  at 7.0s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:20] {1748} INFO - iteration 34, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:21] {1944} INFO -  at 7.0s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:21] {1748} INFO - iteration 35, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:21] {1944} INFO -  at 7.1s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:21] {1748} INFO - iteration 36, current learner rf\n",
      "[flaml.automl: 10-01 12:31:22] {1944} INFO -  at 8.2s,\testimator rf's best error=0.2209,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:22] {1748} INFO - iteration 37, current learner extra_tree\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.4s,\testimator extra_tree's best error=0.2252,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.2500,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 39, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.4s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 40, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.5s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 41, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 42, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.6s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 43, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 44, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.7s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 45, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.8s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 46, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 47, current learner lgbm\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 9.9s,\testimator lgbm's best error=0.1356,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 48, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {1748} INFO - iteration 49, current learner xgboost\n",
      "[flaml.automl: 10-01 12:31:23] {1944} INFO -  at 10.0s,\testimator xgboost's best error=0.2492,\tbest estimator lgbm's best error=0.1356\n",
      "[flaml.automl: 10-01 12:31:23] {2043} INFO - selected model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
      "              learning_rate=0.17402065726724145, max_bin=128,\n",
      "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
      "              objective='regression', reg_alpha=0.0009765625,\n",
      "              reg_lambda=0.006761362450996487, verbose=-1)\n",
      "[flaml.automl: 10-01 12:31:24] {2106} INFO - retrain lgbm for 0.0s\n",
      "[flaml.automl: 10-01 12:31:24] {2110} INFO - retrained model: LGBMRegressor(colsample_bytree=0.6649148062238498,\n",
      "              learning_rate=0.17402065726724145, max_bin=128,\n",
      "              min_child_samples=3, n_estimators=32, num_leaves=9,\n",
      "              objective='regression', reg_alpha=0.0009765625,\n",
      "              reg_lambda=0.006761362450996487, verbose=-1)\n",
      "[flaml.automl: 10-01 12:31:24] {1539} INFO - fit succeeded\n",
      "[flaml.automl: 10-01 12:31:24] {1541} INFO - Time taken to find the best model: 2.950632095336914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.85426879 22.17737651 33.79509964 33.47189557 35.61127167 26.6926382\n",
      " 21.53656446 20.99173684 16.18673463 18.75433976 18.20961633 20.48286627\n",
      " 20.20745331 19.5131759  18.82401423 19.81864373 21.91420674 17.53721008\n",
      " 18.69698259 19.07769813 14.3021372  18.32367106 16.63348583 15.34809335\n",
      " 16.27978499 15.13176242 16.94561436 15.20221211 18.67737191 20.75076542\n",
      " 13.88486622 17.70376242 13.89318927 14.90744983 14.32837615 21.02020963\n",
      " 20.89410764 21.52937191 23.19568492 30.3824402  34.45306735 29.43834549\n",
      " 24.62262048 24.62262048 22.21884844 20.87353145 20.36481607 18.09945043\n",
      " 15.55273032 18.67322033 20.4058421  21.53510487 24.1301244  21.73345138\n",
      " 17.74586736 34.48285914 23.17178682 31.55632404 23.26235097 20.39233374\n",
      " 18.98627393 17.89811291 22.71262836 25.23349363 32.76974079 25.04432847\n",
      " 19.83367435 20.94710592 19.92700235 21.23614492 23.62275307 21.08771163\n",
      " 22.31713619 23.46816704 24.39319272 22.93449232 21.05889974 21.25605159\n",
      " 21.17094097 21.4104049  26.32531539 24.84165632 23.41875466 22.8120377\n",
      " 23.12681643 26.07314549 21.34032521 22.59488629 26.81601064 30.10072674\n",
      " 23.47133879 22.62450376 23.40848205 25.20150116 20.74313622 26.63582822\n",
      " 22.56394496 40.98684448 43.03722064 33.01766391 24.84190574 25.43455857\n",
      " 18.18875737 20.49979008 20.57478854 18.13734457 17.91303198 20.49979008\n",
      " 20.57478854 18.8322359  21.11833105 22.96406162 18.57150096 18.83508569\n",
      " 20.89066811 18.58619509 20.95795201 20.4381487  18.58619509 20.72664127\n",
      " 21.62721157 21.09344795 19.51757484 17.53599996 19.51757484 19.78584094\n",
      " 17.36958717 16.39253423 16.86856532 15.853506   19.71749942 19.35197602\n",
      " 20.07005987 17.39965131 15.92640822 17.14455857 16.51379168 18.47224498\n",
      " 14.38445978 16.3202417  14.36742357 13.09473563 14.46737843 14.73422787\n",
      " 13.79400434 15.41208419 17.4578433  13.90794056 14.77126156 15.18245573\n",
      " 20.57464694 19.22984984 18.55647575 18.00616692 18.32648919 16.20917324\n",
      " 15.94048355 40.44304575 24.93995665 24.55706495 26.17126032 47.56299085\n",
      " 48.57509584 48.92296041 21.89045992 23.47663172 48.88830552 21.21745586\n",
      " 22.24469801 22.12855254 21.21745586 21.21745586 20.71319839 23.99651065\n",
      " 22.20628325 27.61661251 22.24779919 24.35641132 28.82910017 37.4336891\n",
      " 41.82612485 31.40530134 37.2617559  31.63960058 24.06803666 27.95722996\n",
      " 48.31846952 28.85327104 30.14916251 34.44402572 32.43461899 29.21282212\n",
      " 34.58982726 29.81477151 29.09606486 48.42621104 33.91839935 30.81677594\n",
      " 32.76161643 33.0058017  33.0058017  23.35364085 43.33574902 48.15111119\n",
      " 48.42621104 23.7319089  23.12852809 20.08360727 22.292716   18.3152002\n",
      " 20.15144641 18.32878493 21.24073814 25.61968555 20.32169665 23.99488849\n",
      " 22.29871705 25.40375278 20.33285354 23.37310689 27.79745637 20.83190671\n",
      " 26.36215877 26.63632325 45.15579507 45.69665731 43.92509937 30.92171422\n",
      " 45.71273114 31.55492563 22.4680608  32.11251767 44.32137075 45.54983148\n",
      " 27.42782572 22.9617272  25.92533441 32.46382356 23.75605744 25.56397894\n",
      " 24.60210386 20.62465265 21.53758885 25.22345796 19.06214513 17.84017293\n",
      " 21.69626278 20.93442255 22.86047593 26.53529504 23.71037189 26.40330856\n",
      " 32.45002858 40.12441971 21.62770163 20.16906432 43.22019612 48.96580343\n",
      " 36.19046627 31.35388466 34.9431359  44.12722649 46.8156711  32.19902229\n",
      " 34.9431359  22.86211519 29.53873565 47.98290935 46.00178483 21.93765745\n",
      " 21.54793337 25.23142491 24.33883673 35.61319402 31.31696508 32.04267127\n",
      " 33.35308931 31.2559175  25.95200717 34.35510039 46.48696004 35.2163881\n",
      " 45.64080794 49.0327787  30.55331866 22.33257136 21.69757503 23.53652066\n",
      " 23.08245711 24.79937913 31.21276685 34.29118996 28.11258611 23.85939846\n",
      " 21.98861298 27.07522156 25.03558428 19.24341933 24.20354062 30.25026064\n",
      " 26.3510736  24.97967893 24.33108926 32.31816475 34.95139768 27.72254529\n",
      " 34.27356754 28.58064288 26.28401898 20.25949225 19.15765455 23.40595016\n",
      " 19.9069318  22.22895448 23.43789368 19.7967241  17.99129269 18.86799165\n",
      " 21.90295702 21.44864267 23.74221793 23.74221793 21.77357441 19.88044313\n",
      " 23.74861493 26.188891   24.33547333 21.31173366 20.3949194  23.03935223\n",
      " 22.0186464  19.24261422 19.64398129 21.95831249 21.85754325 20.6350395\n",
      " 20.01568444 19.85894712 20.79851822 20.16200017 20.51536951 31.99762077\n",
      " 20.68060523 25.59062004 30.87902463 19.41753345 18.59475908 23.18796837\n",
      " 25.72871802 28.3234078  22.31812575 24.88336613 21.31087817 31.0527335\n",
      " 19.34403778 20.75173519 15.87445808 20.5265433  20.70117246 20.5265433\n",
      " 23.32606114 19.68233643 20.00496907 17.88381107 28.83843559 24.00526687\n",
      " 19.09817287 21.32938439 50.07163944 48.82160629 48.20203737 47.2777543\n",
      " 46.84319485 14.36205747 13.53142624 17.48924424 11.79294408 12.03751809\n",
      " 10.7690999  11.77270178 13.30284038 10.53147486 11.61391857 11.4278251\n",
      "  9.02188405  8.92022632  9.50462006  8.55668465  9.66190862 11.96240478\n",
      " 14.65412353 17.1613234  10.55147356 14.45336107 12.65116497 14.27056086\n",
      " 13.89813053 11.94012717  7.77595912  9.18480867  8.37379402 10.28701903\n",
      " 11.98974767  9.49769797  7.70573926  7.36799143 13.36327035 26.14624567\n",
      " 15.17003545 20.94325541 16.51890218 16.88756044 14.57744105 14.89023868\n",
      "  8.24976464  8.63264333  9.50804859  8.93571718  7.75831071  9.03788871\n",
      " 15.02396264 15.06486095 19.58003642 12.86473687 13.39712744  8.56134775\n",
      " 13.56904967 10.98178079 10.67788405 10.28130892 14.4042725  15.46887706\n",
      " 17.90238886 15.34185827 12.90173312 11.40186526 10.99905848  9.72482922\n",
      "  9.45412739 11.70236191  9.99097952 13.44394369 16.75333771 14.22574262\n",
      " 10.75976886 10.18568291 16.33703165 14.63372832 15.14455645 15.09377379\n",
      " 14.00999287 16.72939436 17.1613234  16.21455097 12.35874932 14.39549294\n",
      " 14.28247556 12.85554461 15.09377379 18.58227987 16.47031642 18.94780328\n",
      " 19.79664167 20.4529397  21.22275643 20.45709742 15.75204166 16.60776586\n",
      " 17.55418796 19.39206231 18.10615643 20.45030404 20.66821931 28.06922267\n",
      " 16.67357885 16.26120202 17.72975505 13.19839222 17.20168726 20.15508873\n",
      " 20.90931887 24.17717967 27.62733557 20.78673312 20.75924242 21.3133487\n",
      " 18.99382477 20.93387158 15.10676681 11.06340755 10.26917289 15.17721649\n",
      " 17.95736363 21.10085132 21.34700608 21.00568378 17.69219141 20.52223098\n",
      " 20.76838574 18.76022157 20.23462213 22.18273078 19.05073131 26.01075867\n",
      " 22.94032743 16.83667178]\n",
      "<flaml.model.LGBMEstimator object at 0x7f0a9df5c610>\n"
     ]
    }
   ],
   "source": [
    "## Regression Problem\n",
    "from flaml import AutoML\n",
    "from sklearn.datasets import load_boston\n",
    "# Initialize an AutoML instance\n",
    "automl = AutoML()\n",
    "# Specify automl goal and constraint\n",
    "automl_settings = {\n",
    "    \"time_budget\": 10,  # in seconds\n",
    "    \"metric\": 'r2',\n",
    "    \"task\": 'regression',\n",
    "    \"log_file_name\": \"boston.log\",\n",
    "}\n",
    "X_train, y_train = load_boston(return_X_y=True)\n",
    "# Train with labeled input data\n",
    "automl.fit(X_train=X_train, y_train=y_train,\n",
    "           **automl_settings)\n",
    "# Predict\n",
    "print(automl.predict(X_train))\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThYM5e7TxriP"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5eRkuWMxUcr",
    "outputId": "73e65552-94a9-4cf8-aaea-125a77d5eba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25.85426879 22.17737651 33.79509964 33.47189557 35.61127167 26.6926382\n",
      " 21.53656446 20.99173684 16.18673463 18.75433976 18.20961633 20.48286627\n",
      " 20.20745331 19.5131759  18.82401423 19.81864373 21.91420674 17.53721008\n",
      " 18.69698259 19.07769813 14.3021372  18.32367106 16.63348583 15.34809335\n",
      " 16.27978499 15.13176242 16.94561436 15.20221211 18.67737191 20.75076542\n",
      " 13.88486622 17.70376242 13.89318927 14.90744983 14.32837615 21.02020963\n",
      " 20.89410764 21.52937191 23.19568492 30.3824402  34.45306735 29.43834549\n",
      " 24.62262048 24.62262048 22.21884844 20.87353145 20.36481607 18.09945043\n",
      " 15.55273032 18.67322033 20.4058421  21.53510487 24.1301244  21.73345138\n",
      " 17.74586736 34.48285914 23.17178682 31.55632404 23.26235097 20.39233374\n",
      " 18.98627393 17.89811291 22.71262836 25.23349363 32.76974079 25.04432847\n",
      " 19.83367435 20.94710592 19.92700235 21.23614492 23.62275307 21.08771163\n",
      " 22.31713619 23.46816704 24.39319272 22.93449232 21.05889974 21.25605159\n",
      " 21.17094097 21.4104049  26.32531539 24.84165632 23.41875466 22.8120377\n",
      " 23.12681643 26.07314549 21.34032521 22.59488629 26.81601064 30.10072674\n",
      " 23.47133879 22.62450376 23.40848205 25.20150116 20.74313622 26.63582822\n",
      " 22.56394496 40.98684448 43.03722064 33.01766391 24.84190574 25.43455857\n",
      " 18.18875737 20.49979008 20.57478854 18.13734457 17.91303198 20.49979008\n",
      " 20.57478854 18.8322359  21.11833105 22.96406162 18.57150096 18.83508569\n",
      " 20.89066811 18.58619509 20.95795201 20.4381487  18.58619509 20.72664127\n",
      " 21.62721157 21.09344795 19.51757484 17.53599996 19.51757484 19.78584094\n",
      " 17.36958717 16.39253423 16.86856532 15.853506   19.71749942 19.35197602\n",
      " 20.07005987 17.39965131 15.92640822 17.14455857 16.51379168 18.47224498\n",
      " 14.38445978 16.3202417  14.36742357 13.09473563 14.46737843 14.73422787\n",
      " 13.79400434 15.41208419 17.4578433  13.90794056 14.77126156 15.18245573\n",
      " 20.57464694 19.22984984 18.55647575 18.00616692 18.32648919 16.20917324\n",
      " 15.94048355 40.44304575 24.93995665 24.55706495 26.17126032 47.56299085\n",
      " 48.57509584 48.92296041 21.89045992 23.47663172 48.88830552 21.21745586\n",
      " 22.24469801 22.12855254 21.21745586 21.21745586 20.71319839 23.99651065\n",
      " 22.20628325 27.61661251 22.24779919 24.35641132 28.82910017 37.4336891\n",
      " 41.82612485 31.40530134 37.2617559  31.63960058 24.06803666 27.95722996\n",
      " 48.31846952 28.85327104 30.14916251 34.44402572 32.43461899 29.21282212\n",
      " 34.58982726 29.81477151 29.09606486 48.42621104 33.91839935 30.81677594\n",
      " 32.76161643 33.0058017  33.0058017  23.35364085 43.33574902 48.15111119\n",
      " 48.42621104 23.7319089  23.12852809 20.08360727 22.292716   18.3152002\n",
      " 20.15144641 18.32878493 21.24073814 25.61968555 20.32169665 23.99488849\n",
      " 22.29871705 25.40375278 20.33285354 23.37310689 27.79745637 20.83190671\n",
      " 26.36215877 26.63632325 45.15579507 45.69665731 43.92509937 30.92171422\n",
      " 45.71273114 31.55492563 22.4680608  32.11251767 44.32137075 45.54983148\n",
      " 27.42782572 22.9617272  25.92533441 32.46382356 23.75605744 25.56397894\n",
      " 24.60210386 20.62465265 21.53758885 25.22345796 19.06214513 17.84017293\n",
      " 21.69626278 20.93442255 22.86047593 26.53529504 23.71037189 26.40330856\n",
      " 32.45002858 40.12441971 21.62770163 20.16906432 43.22019612 48.96580343\n",
      " 36.19046627 31.35388466 34.9431359  44.12722649 46.8156711  32.19902229\n",
      " 34.9431359  22.86211519 29.53873565 47.98290935 46.00178483 21.93765745\n",
      " 21.54793337 25.23142491 24.33883673 35.61319402 31.31696508 32.04267127\n",
      " 33.35308931 31.2559175  25.95200717 34.35510039 46.48696004 35.2163881\n",
      " 45.64080794 49.0327787  30.55331866 22.33257136 21.69757503 23.53652066\n",
      " 23.08245711 24.79937913 31.21276685 34.29118996 28.11258611 23.85939846\n",
      " 21.98861298 27.07522156 25.03558428 19.24341933 24.20354062 30.25026064\n",
      " 26.3510736  24.97967893 24.33108926 32.31816475 34.95139768 27.72254529\n",
      " 34.27356754 28.58064288 26.28401898 20.25949225 19.15765455 23.40595016\n",
      " 19.9069318  22.22895448 23.43789368 19.7967241  17.99129269 18.86799165\n",
      " 21.90295702 21.44864267 23.74221793 23.74221793 21.77357441 19.88044313\n",
      " 23.74861493 26.188891   24.33547333 21.31173366 20.3949194  23.03935223\n",
      " 22.0186464  19.24261422 19.64398129 21.95831249 21.85754325 20.6350395\n",
      " 20.01568444 19.85894712 20.79851822 20.16200017 20.51536951 31.99762077\n",
      " 20.68060523 25.59062004 30.87902463 19.41753345 18.59475908 23.18796837\n",
      " 25.72871802 28.3234078  22.31812575 24.88336613 21.31087817 31.0527335\n",
      " 19.34403778 20.75173519 15.87445808 20.5265433  20.70117246 20.5265433\n",
      " 23.32606114 19.68233643 20.00496907 17.88381107 28.83843559 24.00526687\n",
      " 19.09817287 21.32938439 50.07163944 48.82160629 48.20203737 47.2777543\n",
      " 46.84319485 14.36205747 13.53142624 17.48924424 11.79294408 12.03751809\n",
      " 10.7690999  11.77270178 13.30284038 10.53147486 11.61391857 11.4278251\n",
      "  9.02188405  8.92022632  9.50462006  8.55668465  9.66190862 11.96240478\n",
      " 14.65412353 17.1613234  10.55147356 14.45336107 12.65116497 14.27056086\n",
      " 13.89813053 11.94012717  7.77595912  9.18480867  8.37379402 10.28701903\n",
      " 11.98974767  9.49769797  7.70573926  7.36799143 13.36327035 26.14624567\n",
      " 15.17003545 20.94325541 16.51890218 16.88756044 14.57744105 14.89023868\n",
      "  8.24976464  8.63264333  9.50804859  8.93571718  7.75831071  9.03788871\n",
      " 15.02396264 15.06486095 19.58003642 12.86473687 13.39712744  8.56134775\n",
      " 13.56904967 10.98178079 10.67788405 10.28130892 14.4042725  15.46887706\n",
      " 17.90238886 15.34185827 12.90173312 11.40186526 10.99905848  9.72482922\n",
      "  9.45412739 11.70236191  9.99097952 13.44394369 16.75333771 14.22574262\n",
      " 10.75976886 10.18568291 16.33703165 14.63372832 15.14455645 15.09377379\n",
      " 14.00999287 16.72939436 17.1613234  16.21455097 12.35874932 14.39549294\n",
      " 14.28247556 12.85554461 15.09377379 18.58227987 16.47031642 18.94780328\n",
      " 19.79664167 20.4529397  21.22275643 20.45709742 15.75204166 16.60776586\n",
      " 17.55418796 19.39206231 18.10615643 20.45030404 20.66821931 28.06922267\n",
      " 16.67357885 16.26120202 17.72975505 13.19839222 17.20168726 20.15508873\n",
      " 20.90931887 24.17717967 27.62733557 20.78673312 20.75924242 21.3133487\n",
      " 18.99382477 20.93387158 15.10676681 11.06340755 10.26917289 15.17721649\n",
      " 17.95736363 21.10085132 21.34700608 21.00568378 17.69219141 20.52223098\n",
      " 20.76838574 18.76022157 20.23462213 22.18273078 19.05073131 26.01075867\n",
      " 22.94032743 16.83667178]\n",
      "<flaml.model.LGBMEstimator object at 0x7f0a9df5c610>\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "print(automl.predict(X_train))\n",
    "# Export the best model\n",
    "print(automl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7kvrow81vYL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
